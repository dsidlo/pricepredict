{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pandas_ta as ta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.callbacks import History\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, LSTM, Input, Activation, concatenate\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "global PriceDataCache\n",
    "\n",
    "def predictPrice:\n",
    "    data = yf.download(tickers = 'TSLA', start = '2019-07-19',end = '2024-07-21')\n",
    "    offset = pd.Timedelta(days=-30)\n",
    "    \n",
    "    # Add indicators...\n",
    "    data['RSI']=ta.rsi(data.Close, length=3)\n",
    "    # data['EMAF']=ta.ema(data.Close, length=3)\n",
    "    # data['EMAM']=ta.ema(data.Close, length=6)\n",
    "    # data['EMAS']=ta.ema(data.Close, length=9)\n",
    "    data['DPO']=ta.dpo(data.Close, length=3, centered=True)\n",
    "    \n",
    "    # Add A Target Column\n",
    "    data['Target'] = data['Adj Close']-data.Open\n",
    "    data['Target'] = data['Target'].shift(-1)\n",
    "    # Add a TargetClass Column...\n",
    "    data['TargetClass'] = [1 if data['Target'][i]>0 else 0 for i in range(len(data))]\n",
    "    # Add tje TargetMextC;pse Column...\n",
    "    data['TargetNextClose'] = data['Adj Close'].shift(-1)\n",
    "    \n",
    "    # Remove Rows with Missing Data\n",
    "    data.dropna(inplace=True)\n",
    "    # Reindex the dataframe\n",
    "    data.reset_index(inplace = True)\n",
    "    \n",
    "    # Drop Fields not needed for training input...\n",
    "    # data.drop(['Volume', 'Close', 'Date'], axis=1, inplace=True)\n",
    "    data.drop(['Date'], axis=1, inplace=True)\n",
    "    \n",
    "    # Copy the data DF into a new data_set DF\n",
    "    data_set = data.iloc[:, 0:11]#.values\n",
    "\n",
    "    #Target column Categories\n",
    "    # y: Red Candles\n",
    "    y =[1 if data.Open[i]>data.Close[i] else 0 for i in range(0, len(data))]\n",
    "    # y1: Green Candles\n",
    "    yi = [data.Open[i]-data.Close[i] for i in range(0, len(data))]\n",
    "\n",
    "    # Normalize the data_set DF from money values to a value between 0 and 1...\n",
    "    sc = MinMaxScaler(feature_range=(0,1))\n",
    "    data_set_scaled = sc.fit_transform(data_set)\n",
    "    \n",
    "    X = []\n",
    "\n",
    "    backcandles = 30\n",
    "    for j in range(8): # data_set_scaled[0].size):#2 columns are target not X\n",
    "        X.append([])\n",
    "        for i in range(backcandles, data_set_scaled.shape[0]): # backcandles+2\n",
    "            X[j].append(data_set_scaled[i-backcandles:i, j])\n",
    "    \n",
    "    # Need to understand this area better...\n",
    "    # move axis from 0 to position 2\n",
    "    X=np.moveaxis(X, [0], [2])\n",
    "    \n",
    "    #Erase first elements of y because of backcandles to match X length\n",
    "    #del(yi[0:backcandles])\n",
    "    #X, yi = np.array(X), np.array(yi)\n",
    "    # Choose -1 for last column, classification else -2...\n",
    "    X, yi =np.array(X), np.array(data_set_scaled[backcandles:,-1])\n",
    "    y=np.reshape(yi,(len(yi),1))\n",
    "    #y=sc.fit_transform(yi)\n",
    "    #X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    splitlimit = int(len(X)*0.8)\n",
    "    X_train, X_test = X[:splitlimit], X[splitlimit:]\n",
    "    y_train, y_test = y[:splitlimit], y[splitlimit:]\n",
    "    np.random.seed(10)\n",
    "    \n",
    "    lstm_input = Input(shape=(backcandles, 8), name='lstm_input')\n",
    "    inputs = LSTM(150, name='first_layer')(lstm_input)\n",
    "    inputs = Dense(1, name='dense_layer')(inputs)\n",
    "    output = Activation('linear', name='output')(inputs)\n",
    "    model = Model(inputs=lstm_input, outputs=output)\n",
    "    adam = optimizers.Adam()\n",
    "    model.compile(optimizer=adam, loss='mse')\n",
    "    model.fit(x=X_train, y=y_train, batch_size=15, epochs=15, shuffle=True, validation_split = 0.1)\n"
   ],
   "id": "81de7492d2efdbf5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e78fe8d54fa19d6e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
