{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Optimized vs Non-Optimized\n",
    "\n",
    "Review charts of optimized vs non-optimized models.\n",
    "\n",
    "## Generating Optimized Models...\n",
    "As the Bayesian Hyperparameter Optimization can take some time, it should be run as a standalone process.\n",
    "It should save out the optimized Hyperparameters for each Ticker to a file, and load the optimized Hyperparameters\n",
    "as needed for training the model for a given Ticker.\n"
   ],
   "id": "da7df717a6a98a08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T23:56:40.947662Z",
     "start_time": "2025-01-01T23:56:40.939595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pricepredict import PricePredict\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Direcoty paths...\n",
    "model_dir = '../models/'\n",
    "chart_dir = '../charts/'\n",
    "preds_dir = '../predictions/'\n",
    "\n",
    "# Directory for gui files\n",
    "gui_data = '../gui_data/'\n",
    "# Save/Restore file for the all_df_symbols DataFrame\n",
    "guiAllSymbolsCsv = f'{gui_data}gui_all_symbols.csv'\n",
    "# Pickle files for the PP objects\n",
    "dill_sym_dpps_d = f'{gui_data}sym_dpps.dil'\n",
    "dill_sym_dpps_w = f'{gui_data}sym_dpps_w.dil'\n",
    "dillbk_sym_dpps_d = f'{gui_data}sym_dpps.dil.bk'\n",
    "dillbk_sym_dpps_w = f'{gui_data}sym_dpps_w.dil.bk'\n",
    "# JSON file for the optimized hyperparameters\n",
    "opt_hyperparams = f'{gui_data}ticker_bopts.json'\n",
    "\n",
    "def tst_prediction_analysis(in_ticker, pp_obj=None):\n",
    "        \n",
    "        if pp_obj is None:\n",
    "                # Create an instance of the price prediction object\n",
    "                pp = PricePredict(model_dir='../models/', \n",
    "                                  chart_dir='../charts/', \n",
    "                                  preds_dir='../predictions/')\n",
    "        else:\n",
    "                pp = pp_obj        \n",
    "        \n",
    "        ticker = in_ticker\n",
    "        test_ticker = \"Test-\" + ticker\n",
    "        # Data download dates\n",
    "        train_end_dt = datetime.now()\n",
    "        train_start_dt = (train_end_dt - timedelta(days=365 * 4))\n",
    "        train_end_date = train_end_dt.strftime(\"%Y-%m-%d\")\n",
    "        train_start_date = train_start_dt.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        pred_end_dt = datetime.now()\n",
    "        pred_start_dt = (pred_end_dt - timedelta(days=30 * 3))\n",
    "        pred_start_date = pred_start_dt.strftime(\"%Y-%m-%d\")\n",
    "        pred_end_date = pred_end_dt.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        pp.cache_training_data(ticker, train_start_date, train_end_date, PricePredict.PeriodDaily)\n",
    "        pp.cache_prediction_data(ticker, pred_start_date, pred_end_date, PricePredict.PeriodDaily)\n",
    "        pp.cached_train_predict_report(save_plot=False, show_plot=True)\n",
    "\n",
    "        return pp\n",
    "\n",
    "def do_bayes_opt(in_ticker, pp_obj=None, opt_csv=None,\n",
    "                  only_fetch_opt_data=False, do_optimize=False,\n",
    "                  cache_train=False, cache_predict=False, train_and_predict=False):\n",
    "    if pp_obj is None:\n",
    "        # Create an instance of the price prediction object\n",
    "        pp = PricePredict(model_dir=model_dir,\n",
    "                          chart_dir=chart_dir,\n",
    "                          preds_dir=preds_dir)\n",
    "    else:\n",
    "        pp = pp_obj\n",
    "\n",
    "    # Load data from Yahoo Finance\n",
    "    ticker = in_ticker\n",
    "    # Training Data (Training uses 20% of the latest data for validation)\n",
    "    end_dt = datetime.now()\n",
    "    start_dt = (end_dt - timedelta(days=365 * 4))\n",
    "    end_date = end_dt.strftime(\"%Y-%m-%d\")\n",
    "    start_date = start_dt.strftime(\"%Y-%m-%d\")\n",
    "    # Prediction Data\n",
    "    pred_end_dt = datetime.now()\n",
    "    pred_start_dt = (pred_end_dt - timedelta(days=30 * 3))\n",
    "    pred_end_date = pred_end_dt.strftime(\"%Y-%m-%d\")\n",
    "    pred_start_date = pred_start_dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    if only_fetch_opt_data:\n",
    "        data, pp.features = pp.fetch_data_yahoo(ticker, start_date, end_date)\n",
    "\n",
    "        # Augment the data with additional indicators/features\n",
    "        if data is None:\n",
    "            print(f\"'Close' column not found in {ticker}'s data. Skipping...\")\n",
    "            return None\n",
    "\n",
    "        return pp\n",
    "\n",
    "    if do_optimize:\n",
    "        aug_data, features, targets, dates_data = pp.augment_data(pp.orig_data, 0)\n",
    "\n",
    "        # Scale the data so the model can use it more effectively\n",
    "        scaled_data, scaler = pp.scale_data(aug_data)\n",
    "\n",
    "        # Prepare the scaled data for model inputs\n",
    "        X, y = pp.prep_model_inputs(scaled_data, pp.features)\n",
    "\n",
    "        # Train the model\n",
    "        model, y_pred, mse = pp.train_model(X, y)\n",
    "\n",
    "        # Perform Bayesian optimization\n",
    "        pp.bayesian_optimization(X, y, opt_csv=opt_csv)\n",
    "\n",
    "    if cache_train:\n",
    "        pp.cache_training_data(ticker, start_date, end_date, PricePredict.PeriodDaily)\n",
    "    if cache_predict:\n",
    "        pp.cache_prediction_data(ticker, pred_start_date, pred_end_date, PricePredict.PeriodDaily)\n",
    "    if train_and_predict:\n",
    "        # Training, will load last saved model which is the optimized model.\n",
    "        pp.cached_train_predict_report(force_training=False, save_plot=False, show_plot=True)\n",
    "\n",
    "    return pp\n",
    "        "
   ],
   "id": "fb87a522b518368a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Review Optimized vs Non-Optimized Models Predictions Visually\n",
    "\n",
    "Generate a Prediction Analysis Chart for one Ticker and Optimize the Model's Hyperparameters\n"
   ],
   "id": "aba76bf447c37134"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T23:56:47.186375Z",
     "start_time": "2025-01-01T23:56:46.153126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "ticker = 'AAPL'\n",
    "\n",
    "pp1 = tst_prediction_analysis(ticker)\n",
    "pp2 = do_bayes_opt(ticker)\n",
    "pp2 = tst_prediction_analysis(ticker, pp_obj=pp2)\n",
    "\n",
    "print(f\"Optimized Model Hyperparameters: {pp2.bayes_opt_hypers}\")"
   ],
   "id": "46e019eb57c53dcd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Error: Predicting Price: Input 0 of layer \"functional_19\" is incompatible with the layer: expected shape=(None, 15, 13), found shape=(32, 15, 19)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m ticker \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAAPL\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 3\u001B[0m pp1 \u001B[38;5;241m=\u001B[39m \u001B[43mtst_prediction_analysis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mticker\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m pp2 \u001B[38;5;241m=\u001B[39m do_bayes_opt(ticker)\n\u001B[1;32m      5\u001B[0m pp2 \u001B[38;5;241m=\u001B[39m tst_prediction_analysis(ticker, pp_obj\u001B[38;5;241m=\u001B[39mpp2)\n",
      "Cell \u001B[0;32mIn[9], line 46\u001B[0m, in \u001B[0;36mtst_prediction_analysis\u001B[0;34m(in_ticker, pp_obj)\u001B[0m\n\u001B[1;32m     44\u001B[0m pp\u001B[38;5;241m.\u001B[39mcache_training_data(ticker, train_start_date, train_end_date, PricePredict\u001B[38;5;241m.\u001B[39mPeriodDaily)\n\u001B[1;32m     45\u001B[0m pp\u001B[38;5;241m.\u001B[39mcache_prediction_data(ticker, pred_start_date, pred_end_date, PricePredict\u001B[38;5;241m.\u001B[39mPeriodDaily)\n\u001B[0;32m---> 46\u001B[0m \u001B[43mpp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcached_train_predict_report\u001B[49m\u001B[43m(\u001B[49m\u001B[43msave_plot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_plot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pp\n",
      "File \u001B[0;32m~/workspace/pricepredict/lib/pricepredict.py:1059\u001B[0m, in \u001B[0;36mPricePredict.cached_train_predict_report\u001B[0;34m(self, force_training, no_report, save_plot, show_plot)\u001B[0m\n\u001B[1;32m   1054\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_model(ticker\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mticker,\n\u001B[1;32m   1055\u001B[0m                         date_start\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdateStart_train,\n\u001B[1;32m   1056\u001B[0m                         date_end\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdateEnd_train)\n\u001B[1;32m   1058\u001B[0m \u001B[38;5;66;03m# At this point, we have loaded a model.\u001B[39;00m\n\u001B[0;32m-> 1059\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcached_predict_report\u001B[49m\u001B[43m(\u001B[49m\u001B[43mno_report\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mno_report\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_plot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_plot\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_plot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_plot\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/pricepredict/lib/pricepredict.py:1095\u001B[0m, in \u001B[0;36mPricePredict.cached_predict_report\u001B[0;34m(self, no_report, save_plot, show_plot)\u001B[0m\n\u001B[1;32m   1092\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict_price(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mX)\n\u001B[1;32m   1093\u001B[0m \u001B[38;5;66;03m# Perform data alignment on the prediction data.\u001B[39;00m\n\u001B[1;32m   1094\u001B[0m \u001B[38;5;66;03m# Doing so makes use the the prediction deltas rather than the actual values.\u001B[39;00m\n\u001B[0;32m-> 1095\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madjust_prediction\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1097\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m no_report \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;124;03m    - Produce a prediction chart.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;124;03m    - Save the prediction data to a file or database.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1104\u001B[0m \u001B[38;5;124;03m    - Save the Seasonality Decomposition to a file or database.\u001B[39;00m\n\u001B[1;32m   1105\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
      "File \u001B[0;32m~/workspace/pricepredict/lib/pricepredict.py:1551\u001B[0m, in \u001B[0;36mPricePredict.adjust_prediction\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1548\u001B[0m pred_low \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpred_low\n\u001B[1;32m   1550\u001B[0m \u001B[38;5;66;03m# Gather the target data for the test period.\u001B[39;00m\n\u001B[0;32m-> 1551\u001B[0m target_close \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39morig_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAdj Close\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m-\u001B[39m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mpred_close\u001B[49m\u001B[43m)\u001B[49m:])\n\u001B[1;32m   1552\u001B[0m target_high \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39morig_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHigh\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m-\u001B[39m\u001B[38;5;28mlen\u001B[39m(pred_high):])\n\u001B[1;32m   1553\u001B[0m target_low \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39morig_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLow\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m-\u001B[39m\u001B[38;5;28mlen\u001B[39m(pred_low):])\n",
      "\u001B[0;31mTypeError\u001B[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Generate a CSV file of the optimized hyperparameters for each Ticker\n",
    "\n",
    "### * * * This codes does not run as it produces too much output * * *"
   ],
   "id": "dafab524fc5ba016"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import futureproof as fp\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "tickers = [ 'AAPL', 'ABT', 'ACN', 'ADBE', 'ADM', 'ADP', 'AIG', 'ALKS', 'ALL', 'AMGN', 'AMX', 'AMZN', 'ANTM.JK', 'AON', 'APD', 'APTV', 'AVGO', 'AXON', 'AXP', 'BA', 'BAC', 'BAX', 'BKNG', 'BLK', 'BRK-B', 'CAT', 'CB', 'CCI', 'CI', 'CL', 'CLDX', 'CLS', 'CLSK', 'CMCSA', 'CNC', 'CRM', 'CRSP', 'CSCO', 'CSX', 'CVX', 'DHR', 'DIS', 'DUK', 'ECL', 'EGIO', 'EL', 'EMR', 'EOG', 'ERIC', 'EURUSD=X', 'EXAS', 'EXEL', 'FOLD', 'FXI', 'FXP', 'GBPUSD=X', 'GC=F', 'GD', 'GE', 'GILD', 'GLPG', 'GOOG', 'GOOGL', 'HAE', 'HD', 'HON', 'IART', 'IBM', 'IMAX', 'INTC', 'INTU', 'IRTC', 'ISRG', 'ITW', 'JAZZ', 'JD', 'JNJ', 'JPM', 'JPYUSD=X', 'KO', 'LIN', 'LIVN', 'LLY', 'LMT', 'LOW', 'LRCX', 'LSCC', 'MA', 'MASI', 'MCD', 'MDLZ', 'MDT', 'META', 'MMM', 'MO', 'MRK', 'MRVL', 'MSFT', 'MTCH', 'NEE', 'NFLX', 'NKE', 'NNDM', 'NOW', 'NVCR', 'NVDA', 'ORCL', 'PACB', 'PEP', 'PFE', 'PG', 'PLD', 'PNC', 'PSA', 'PTCT', 'PYPL', 'QCOM', 'RTX', 'SBUX', 'SCHW', 'SEDG', 'SO', 'SPGI', 'SYK', 'SYY', 'T', 'TMO', 'TRV', 'TSLA', 'TXN', 'UCTT', 'UNH', 'UPS', 'USB', 'V', 'VRTX', 'VZ', 'WM', 'WMT', 'WOLF', 'XAB=F', 'XAE=F', 'XAF=F', 'XAI=F', 'XAK=F', 'XAU=F', 'XNCR', 'XOM', 'ZM', '^DJI', '^GSPC', '^IXIC', '^N225', '^XAX' ]\n",
    "\n",
    "executor = fp.ThreadPoolExecutor(max_workers=15)\n",
    "ticker_pp = {}\n",
    "with fp.TaskManager(executor) as tm:\n",
    "        for ticker in tqdm_notebook(tickers, desc=\"Submitting Models\", unit=\"Ticker\"):\n",
    "                # Sync: Pull in Training and Prediction Data for each Ticker\n",
    "                print(f\"Pulling Optimization data for {ticker}...\")\n",
    "                pp = tst_bayes_opt(ticker, only_fetch_opt_data=True)\n",
    "                ticker_pp[ticker] = pp\n",
    "        for ticker in tqdm_notebook(tickers, desc=\"Submitting Models\", unit=\"Ticker\"):\n",
    "                # Async: Optimize the Model's Hyperparameters for each Ticker\n",
    "                print(f\"Optimizing model for {ticker}...\")\n",
    "                pp = ticker_pp[ticker]\n",
    "                tm.submit(tst_bayes_opt, ticker, pp_obj=pp, do_optimize=True)        \n",
    "        print(\"Waiting for tasks to complete...\")\n",
    "        with open(f\"./ticker_bopts.json\", 'w') as f:\n",
    "                for future in tm.as_completed():\n",
    "                        pp = future.result()\n",
    "                        # Write out the optimized hyperparameters to a JSON file\n",
    "                        f.write(f\"{{ {pp.ticker}: {pp.bayes_opt_hypers} }}\")\n",
    "                        print(f\"Completed Hyperparameters Optimization: {pp.ticker}\")\n"
   ],
   "id": "1201d179a19c79ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m45s\u001B[0m 605ms/step - loss: 0.0140\n",
      "\u001B[1m30/57\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m13s\u001B[0m 485ms/step - loss: 0.0119| \u001B[39m6        \u001B[39m | \u001B[39m-0.01343 \u001B[39m | \u001B[39m0.01916  \u001B[39m | \u001B[39m0.2217   \u001B[39m | \u001B[39m149.5    \u001B[39m |\n",
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m43s\u001B[0m 582ms/step - loss: 0.0260\n",
      "\u001B[1m53/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m2s\u001B[0m 552ms/step - loss: 0.0077| \u001B[39m6        \u001B[39m | \u001B[39m-0.02527 \u001B[39m | \u001B[39m0.01916  \u001B[39m | \u001B[39m0.2217   \u001B[39m | \u001B[39m149.5    \u001B[39m |\n",
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m42s\u001B[0m 579ms/step - loss: 0.0102\n",
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m40s\u001B[0m 546ms/step - loss: 0.0075\n",
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m42s\u001B[0m 561ms/step - loss: 0.0077\n",
      "\u001B[1m50/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m3s\u001B[0m 505ms/step - loss: 0.0105| \u001B[35m6        \u001B[39m | \u001B[35m-0.007578\u001B[39m | \u001B[35m0.01916  \u001B[39m | \u001B[35m0.2217   \u001B[39m | \u001B[35m149.5    \u001B[39m |\n",
      "\u001B[1m51/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m3s\u001B[0m 520ms/step - loss: 0.0053| \u001B[39m6        \u001B[39m | \u001B[39m-0.01004 \u001B[39m | \u001B[39m0.01916  \u001B[39m | \u001B[39m0.2217   \u001B[39m | \u001B[39m149.5    \u001B[39m |\n",
      "\u001B[1m52/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m2s\u001B[0m 517ms/step - loss: 0.0053| \u001B[39m6        \u001B[39m | \u001B[39m-0.00773 \u001B[39m | \u001B[39m0.01916  \u001B[39m | \u001B[39m0.2217   \u001B[39m | \u001B[39m149.5    \u001B[39m |\n",
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m39s\u001B[0m 535ms/step - loss: 0.0053\n",
      "\u001B[1m48/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m4s\u001B[0m 507ms/step - loss: 0.0119| \u001B[35m6        \u001B[39m | \u001B[35m-0.005633\u001B[39m | \u001B[35m0.01916  \u001B[39m | \u001B[35m0.2217   \u001B[39m | \u001B[35m149.5    \u001B[39m |\n",
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m37s\u001B[0m 527ms/step - loss: 0.0104\n",
      "\u001B[1m49/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m4s\u001B[0m 509ms/step - loss: 0.0119| \u001B[39m6        \u001B[39m | \u001B[39m-0.01014 \u001B[39m | \u001B[39m0.01916  \u001B[39m | \u001B[39m0.2217   \u001B[39m | \u001B[39m149.5    \u001B[39m |\n",
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m39s\u001B[0m 538ms/step - loss: 0.0109\n",
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m40s\u001B[0m 568ms/step - loss: 0.0124\n",
      "\u001B[1m 7/57\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m27s\u001B[0m 552ms/step - loss: 0.0182| \u001B[39m6        \u001B[39m | \u001B[39m-0.01124 \u001B[39m | \u001B[39m0.01916  \u001B[39m | \u001B[39m0.2217   \u001B[39m | \u001B[39m149.5    \u001B[39m |\n",
      "| \u001B[39m6        \u001B[39m | \u001B[39m-0.01292 \u001B[39m | \u001B[39m0.01916  \u001B[39m | \u001B[39m0.2217   \u001B[39m | \u001B[39m149.5    \u001B[39m |\n",
      "\u001B[1m56/56\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 495ms/step - loss: 0.0068\n",
      "\u001B[1m12/57\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m22s\u001B[0m 497ms/step - loss: 0.0173| \u001B[39m6        \u001B[39m | \u001B[39m-0.00653 \u001B[39m | \u001B[39m0.01916  \u001B[39m | \u001B[39m0.2217   \u001B[39m | \u001B[39m149.5    \u001B[39m |\n",
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 520ms/step - loss: 0.0119\n",
      "\u001B[1m14/57\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m21s\u001B[0m 494ms/step - loss: 0.0170| \u001B[39m6        \u001B[39m | \u001B[39m-0.01202 \u001B[39m | \u001B[39m0.01916  \u001B[39m | \u001B[39m0.2217   \u001B[39m | \u001B[39m149.5    \u001B[39m |\n",
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m38s\u001B[0m 527ms/step - loss: 0.0169\n",
      "\u001B[1m 8/57\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m26s\u001B[0m 533ms/step - loss: 0.0113| \u001B[39m6        \u001B[39m | \u001B[39m-0.01712 \u001B[39m | \u001B[39m0.01916  \u001B[39m | \u001B[39m0.2217   \u001B[39m | \u001B[39m149.5    \u001B[39m |\n",
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 679ms/step - loss: 0.0040\n",
      "\u001B[1m51/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m4s\u001B[0m 670ms/step - loss: 0.0107| \u001B[35m6        \u001B[39m | \u001B[35m-0.004146\u001B[39m | \u001B[35m0.01916  \u001B[39m | \u001B[35m0.2217   \u001B[39m | \u001B[35m149.5    \u001B[39m |\n",
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 656ms/step - loss: 0.0106\n",
      "| \u001B[39m6        \u001B[39m | \u001B[39m-0.01023 \u001B[39m | \u001B[39m0.01916  \u001B[39m | \u001B[39m0.2217   \u001B[39m | \u001B[39m149.5    \u001B[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m 2/57\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m21s\u001B[0m 398ms/step - loss: 0.0993"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d1d63f4a14d87318"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
