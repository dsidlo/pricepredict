{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Optimized vs Non-Optimized\n",
    "\n",
    "Review charts of optimized vs non-optimized models.\n",
    "\n",
    "## Generating Optimized Models...\n",
    "As the Bayesian Hyperparameter Optimization can take some time, it should be run as a standalone process.\n",
    "It should save out the optimized Hyperparameters for each Ticker to a file, and load the optimized Hyperparameters\n",
    "as needed for training the model for a given Ticker.\n"
   ],
   "id": "da7df717a6a98a08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T09:19:46.438481Z",
     "start_time": "2024-10-28T09:19:46.305986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pricepredict import PricePredict\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def tst_prediction_analysis(in_ticker):\n",
    "        \n",
    "        # Create an instance of the price prediction object\n",
    "        pp = PricePredict(model_dir='../models/', \n",
    "                          chart_dir='../charts/', \n",
    "                          preds_dir='../predictions/')\n",
    "        \n",
    "        ticker = in_ticker\n",
    "        test_ticker = \"Test-\" + ticker\n",
    "        # Data download dates\n",
    "        start_date = \"2015-01-01\"\n",
    "        end_date = \"2023-12-31\"\n",
    "        pred_start_date = \"2024-01-01\"\n",
    "        pred_end_date = \"2024-10-25\"\n",
    "        \n",
    "        pp.cache_training_data(ticker, start_date, end_date, PricePredict.PeriodDaily)\n",
    "        pp.cache_prediction_data(ticker, pred_start_date, pred_end_date, PricePredict.PeriodDaily)\n",
    "        pp.cached_train_predict_report(save_plot=False, show_plot=True)\n",
    "\n",
    "        return pp\n",
    "\n",
    "def tst_bayes_opt(in_ticker, pp_obj=None, opt_csv=None,\n",
    "                  only_fetch_opt_data=False, do_optimize=False,          \n",
    "                  cache_train=False, cache_predict=False, train_and_predict=False):\n",
    "        \n",
    "        if pp_obj is None:\n",
    "                # Create an instance of the price prediction object\n",
    "                pp = PricePredict(model_dir='../models/',\n",
    "                                  chart_dir='../charts/', \n",
    "                                  preds_dir='../predictions/')\n",
    "        else:\n",
    "                pp = pp_obj\n",
    "            \n",
    "        # Load data from Yahoo Finance\n",
    "        ticker = in_ticker\n",
    "        start_date = \"2015-01-01\"\n",
    "        end_date = \"2023-12-31\"\n",
    "        pred_start_date = \"2024-01-01\"\n",
    "        pred_end_date = \"2024-10-25\"\n",
    "\n",
    "        if only_fetch_opt_data:\n",
    "                data, pp.features = pp.fetch_data_yahoo(ticker, start_date, end_date)\n",
    "        \n",
    "                # Augment the data with additional indicators/features\n",
    "                if data is None:\n",
    "                        print(f\"'Close' column not found in {ticker}'s data. Skipping...\")\n",
    "                        return None\n",
    "                \n",
    "                return pp\n",
    "        \n",
    "        if do_optimize:\n",
    "                aug_data, features, targets, dates_data = pp.augment_data(pp.orig_data, 0)\n",
    "        \n",
    "                # Scale the data so the model can use it more effectively\n",
    "                scaled_data, scaler = pp.scale_data(aug_data)\n",
    "        \n",
    "                # Prepare the scaled data for model inputs\n",
    "                X, y = pp.prep_model_inputs(scaled_data, pp.features)\n",
    "        \n",
    "                # Use a small batch size and epochs to test the model training\n",
    "                pp.epochs = 3\n",
    "                pp.batch_size = 1\n",
    "\n",
    "                # Train the model\n",
    "                model, y_pred, mse = pp.train_model(X, y)\n",
    "\n",
    "                # Perform Bayesian optimization\n",
    "                pp.bayesian_optimization(X, y, opt_csv=opt_csv)\n",
    "\n",
    "        if cache_train:\n",
    "                pp.cache_training_data(ticker, start_date, end_date, PricePredict.PeriodDaily)\n",
    "        if cache_predict:   \n",
    "                pp.cache_prediction_data(ticker, pred_start_date, pred_end_date, PricePredict.PeriodDaily)\n",
    "        if train_and_predict:    \n",
    "                pp.cached_train_predict_report(save_plot=False, show_plot=True)\n",
    "\n",
    "        return pp                \n",
    "        "
   ],
   "id": "fb87a522b518368a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Review Optimized vs Non-Optimized Models Predictions Visually\n",
    "\n",
    "Generate a Prediction Analysis Chart for one Ticker and Optimize the Model's Hyperparameters\n"
   ],
   "id": "aba76bf447c37134"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "ticker = 'AAPL'\n",
    "\n",
    "pp1 = tst_prediction_analysis(ticker)\n",
    "pp2 = tst_bayes_opt(ticker, train=True, predict=True, plot_chart=True)\n",
    "print(f\"Optimized Model Hyperparameters: {pp2.bayes_opt_hypers}\")"
   ],
   "id": "46e019eb57c53dcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Generate a CSV file of the optimized hyperparameters for each Ticker\n",
    "\n",
    "### * * * This codes does not run as it produces too much output * * *"
   ],
   "id": "dafab524fc5ba016"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import futureproof as fp\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "tickers = [ 'AAPL', 'ABT', 'ACN', 'ADBE', 'ADM', 'ADP', 'AIG', 'ALKS', 'ALL', 'AMGN', 'AMX', 'AMZN', 'ANTM.JK', 'AON', 'APD', 'APTV', 'AVGO', 'AXON', 'AXP', 'BA', 'BAC', 'BAX', 'BKNG', 'BLK', 'BRK-B', 'CAT', 'CB', 'CCI', 'CI', 'CL', 'CLDX', 'CLS', 'CLSK', 'CMCSA', 'CNC', 'CRM', 'CRSP', 'CSCO', 'CSX', 'CVX', 'DHR', 'DIS', 'DUK', 'ECL', 'EGIO', 'EL', 'EMR', 'EOG', 'ERIC', 'EURUSD=X', 'EXAS', 'EXEL', 'FOLD', 'FXI', 'FXP', 'GBPUSD=X', 'GC=F', 'GD', 'GE', 'GILD', 'GLPG', 'GOOG', 'GOOGL', 'HAE', 'HD', 'HON', 'IART', 'IBM', 'IMAX', 'INTC', 'INTU', 'IRTC', 'ISRG', 'ITW', 'JAZZ', 'JD', 'JNJ', 'JPM', 'JPYUSD=X', 'KO', 'LIN', 'LIVN', 'LLY', 'LMT', 'LOW', 'LRCX', 'LSCC', 'MA', 'MASI', 'MCD', 'MDLZ', 'MDT', 'META', 'MMM', 'MO', 'MRK', 'MRVL', 'MSFT', 'MTCH', 'NEE', 'NFLX', 'NKE', 'NNDM', 'NOW', 'NVCR', 'NVDA', 'ORCL', 'PACB', 'PEP', 'PFE', 'PG', 'PLD', 'PNC', 'PSA', 'PTCT', 'PYPL', 'QCOM', 'RTX', 'SBUX', 'SCHW', 'SEDG', 'SO', 'SPGI', 'SYK', 'SYY', 'T', 'TMO', 'TRV', 'TSLA', 'TXN', 'UCTT', 'UNH', 'UPS', 'USB', 'V', 'VRTX', 'VZ', 'WM', 'WMT', 'WOLF', 'XAB=F', 'XAE=F', 'XAF=F', 'XAI=F', 'XAK=F', 'XAU=F', 'XNCR', 'XOM', 'ZM', '^DJI', '^GSPC', '^IXIC', '^N225', '^XAX' ]\n",
    "\n",
    "executor = fp.ThreadPoolExecutor(max_workers=15)\n",
    "ticker_pp = {}\n",
    "with fp.TaskManager(executor) as tm:\n",
    "        for ticker in tqdm_notebook(tickers, desc=\"Submitting Models\", unit=\"Ticker\"):\n",
    "                # Sync: Pull in Training and Prediction Data for each Ticker\n",
    "                print(f\"Pulling Optimization data for {ticker}...\")\n",
    "                pp = tst_bayes_opt(ticker, only_fetch_opt_data=True)\n",
    "                ticker_pp[ticker] = pp\n",
    "        for ticker in tqdm_notebook(tickers, desc=\"Submitting Models\", unit=\"Ticker\"):\n",
    "                # Async: Optimize the Model's Hyperparameters for each Ticker\n",
    "                print(f\"Optimizing model for {ticker}...\")\n",
    "                pp = ticker_pp[ticker]\n",
    "                tm.submit(tst_bayes_opt, ticker, pp_obj=pp, do_optimize=True)        \n",
    "        print(\"Waiting for tasks to complete...\")\n",
    "        with open(f\"./ticker_bopts.json\", 'w') as f:\n",
    "                for future in tm.as_completed():\n",
    "                        pp = future.result()\n",
    "                        # Write out the optimized hyperparameters to a JSON file\n",
    "                        f.write(f\"{{ {pp.ticker}: {pp.bayes_opt_hypers} }}\")\n",
    "                        print(f\"Completed Hyperparameters Optimization: {pp.ticker}\")\n"
   ],
   "id": "1201d179a19c79ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m45s\u001B[0m 605ms/step - loss: 0.0140\n",
      "\u001B[1m30/57\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m13s\u001B[0m 485ms/step - loss: 0.0119| \u001B[39m6        \u001B[39m | \u001B[39m-0.01343 \u001B[39m | \u001B[39m0.01916  \u001B[39m | \u001B[39m0.2217   \u001B[39m | \u001B[39m149.5    \u001B[39m |\n",
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m43s\u001B[0m 582ms/step - loss: 0.0260\n",
      "\u001B[1m53/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m2s\u001B[0m 552ms/step - loss: 0.0077| \u001B[39m6        \u001B[39m | \u001B[39m-0.02527 \u001B[39m | \u001B[39m0.01916  \u001B[39m | \u001B[39m0.2217   \u001B[39m | \u001B[39m149.5    \u001B[39m |\n",
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m42s\u001B[0m 579ms/step - loss: 0.0102\n",
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m40s\u001B[0m 546ms/step - loss: 0.0075\n",
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m42s\u001B[0m 561ms/step - loss: 0.0077\n",
      "\u001B[1m50/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m3s\u001B[0m 505ms/step - loss: 0.0105| \u001B[35m6        \u001B[39m | \u001B[35m-0.007578\u001B[39m | \u001B[35m0.01916  \u001B[39m | \u001B[35m0.2217   \u001B[39m | \u001B[35m149.5    \u001B[39m |\n",
      "\u001B[1m51/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m3s\u001B[0m 520ms/step - loss: 0.0053| \u001B[39m6        \u001B[39m | \u001B[39m-0.01004 \u001B[39m | \u001B[39m0.01916  \u001B[39m | \u001B[39m0.2217   \u001B[39m | \u001B[39m149.5    \u001B[39m |\n",
      "\u001B[1m52/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m2s\u001B[0m 517ms/step - loss: 0.0053| \u001B[39m6        \u001B[39m | \u001B[39m-0.00773 \u001B[39m | \u001B[39m0.01916  \u001B[39m | \u001B[39m0.2217   \u001B[39m | \u001B[39m149.5    \u001B[39m |\n",
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m39s\u001B[0m 535ms/step - loss: 0.0053\n",
      "\u001B[1m48/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m4s\u001B[0m 507ms/step - loss: 0.0119| \u001B[35m6        \u001B[39m | \u001B[35m-0.005633\u001B[39m | \u001B[35m0.01916  \u001B[39m | \u001B[35m0.2217   \u001B[39m | \u001B[35m149.5    \u001B[39m |\n",
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m37s\u001B[0m 527ms/step - loss: 0.0104\n",
      "\u001B[1m49/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m4s\u001B[0m 509ms/step - loss: 0.0119| \u001B[39m6        \u001B[39m | \u001B[39m-0.01014 \u001B[39m | \u001B[39m0.01916  \u001B[39m | \u001B[39m0.2217   \u001B[39m | \u001B[39m149.5    \u001B[39m |\n",
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m39s\u001B[0m 538ms/step - loss: 0.0109\n",
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m40s\u001B[0m 568ms/step - loss: 0.0124\n",
      "\u001B[1m 7/57\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m27s\u001B[0m 552ms/step - loss: 0.0182| \u001B[39m6        \u001B[39m | \u001B[39m-0.01124 \u001B[39m | \u001B[39m0.01916  \u001B[39m | \u001B[39m0.2217   \u001B[39m | \u001B[39m149.5    \u001B[39m |\n",
      "| \u001B[39m6        \u001B[39m | \u001B[39m-0.01292 \u001B[39m | \u001B[39m0.01916  \u001B[39m | \u001B[39m0.2217   \u001B[39m | \u001B[39m149.5    \u001B[39m |\n",
      "\u001B[1m56/56\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 495ms/step - loss: 0.0068\n",
      "\u001B[1m12/57\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m22s\u001B[0m 497ms/step - loss: 0.0173| \u001B[39m6        \u001B[39m | \u001B[39m-0.00653 \u001B[39m | \u001B[39m0.01916  \u001B[39m | \u001B[39m0.2217   \u001B[39m | \u001B[39m149.5    \u001B[39m |\n",
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 520ms/step - loss: 0.0119\n",
      "\u001B[1m14/57\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m21s\u001B[0m 494ms/step - loss: 0.0170| \u001B[39m6        \u001B[39m | \u001B[39m-0.01202 \u001B[39m | \u001B[39m0.01916  \u001B[39m | \u001B[39m0.2217   \u001B[39m | \u001B[39m149.5    \u001B[39m |\n",
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m38s\u001B[0m 527ms/step - loss: 0.0169\n",
      "\u001B[1m 8/57\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m26s\u001B[0m 533ms/step - loss: 0.0113| \u001B[39m6        \u001B[39m | \u001B[39m-0.01712 \u001B[39m | \u001B[39m0.01916  \u001B[39m | \u001B[39m0.2217   \u001B[39m | \u001B[39m149.5    \u001B[39m |\n",
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 679ms/step - loss: 0.0040\n",
      "\u001B[1m51/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m4s\u001B[0m 670ms/step - loss: 0.0107| \u001B[35m6        \u001B[39m | \u001B[35m-0.004146\u001B[39m | \u001B[35m0.01916  \u001B[39m | \u001B[35m0.2217   \u001B[39m | \u001B[35m149.5    \u001B[39m |\n",
      "\u001B[1m57/57\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 656ms/step - loss: 0.0106\n",
      "| \u001B[39m6        \u001B[39m | \u001B[39m-0.01023 \u001B[39m | \u001B[39m0.01916  \u001B[39m | \u001B[39m0.2217   \u001B[39m | \u001B[39m149.5    \u001B[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m 2/57\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m21s\u001B[0m 398ms/step - loss: 0.0993"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d1d63f4a14d87318"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
