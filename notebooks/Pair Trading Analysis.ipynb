{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d05a19bb0dddc4ea",
   "metadata": {},
   "source": [
    "# Pair Trading Analysis\n",
    "  \n",
    "Given a pair of stocks that are Conintegrated, grab their PricePredict Objects from the\n",
    "ppo/ directory and plot a median/spread graph of the two stocks. This will allow us to see\n",
    "how the two stocks are moving relative to each other and if there are any opportunities to\n",
    "trade the spread between the two stocks.\n",
    "\n",
    "Run a simple trading simulation that uses a strategy of trading the 2 stocks at the same time\n",
    "as follows:\n",
    "* Opening a Pairs Trade...\n",
    "    * When the 2 stocks diverge and the stock that is overvalued is more than the historical standard deviation\n",
    "      from the mean (based on N most profitable moves) and the undervalued stock is more than the historical \n",
    "      standard deviation from the mean (etc.). \n",
    "        * Sell the overvalued stock and buy the undervalued stock.\n",
    "          Only do these trades if the prediction for the next day indicates that the overvalued stock\n",
    "          is going to go down and the undervalued stock is going to go up on on the current timeframe,\n",
    "          and on the next higher timeframe (weekly, given a daily trading timeframe).\n",
    "          Then buy/sell the stocks at the opening price of the next day.\n",
    "        * Use additional indicators that indicate a reversal in the spread (as needed). \n",
    "    * Do we trade from convergence?\n",
    "        * It does not make sense to trade from convergence, as it is difficult to determine which\n",
    "          stock to go long on and which stock to go short on.\n",
    "        * We should only trade from divergence, as we can determine which stock is overvalued and which\n",
    "          stock is undervalued. \n",
    "* Closing a Pairs Trade...\n",
    "    * Given an open Pairs Trade that started from a Spread Divergence... \n",
    "        * We wait for the spread to converge to the median and then close the trade.\n",
    "        * We then calculate the profit/loss of the trade and add it to the total profit/loss.\n",
    "* How to choose going long vs going short (one stock will be long and the other short)...\n",
    "    * The Spread calculation is essentially the difference between the two stocks. Stock_A - Stock_B.\n",
    "        * As Stock_A goes up and Stock_B goes down, the spread will increase (go up in the spread graph).\n",
    "        * As Stock_A goes down and Stock_B goes up, the spread will decrease (go down in the spread graph).    \n",
    "    * If the spread is above 2 standard deviations from the mean, we go short on Stock_A and long on Stock_B.\n",
    "    * If the spread is below 2 standard deviations from the mean, we go long on Stock_A and short on Stock_B.\n",
    "* How much to trade...\n",
    "    * We use the Hedge Ratio to determine how much of each stock to trade.\n",
    "        * The Hedge Ratio is the Beta from the OLS regression of Stock_A on Stock_B.\n",
    "    * The Hedge Ratio is the amount of Stock_B that is needed to hedge the risk of Stock_A.\n",
    "        * If the Hedge Ratio is 1.5, then we would trade 1.5 shares of Stock_B for every 1 share of Stock_A.\n",
    "        * If the Hedge Ratio is negative (-1.5), then for every 1 share of Stock_B, we would trade 1.5 shares of Stock_A.\n",
    "\n",
    "## Questions...\n",
    "\n",
    "* Which is a stronger indicator of Cointegration...\n",
    "    * Weekly or Daily?\n",
    "    * Both are useful much the way a weekly prediction indicates the longer term trend and a daily prediction\n",
    "      indicates the shorter term trend.\n",
    "\n",
    "## Insights...\n",
    "\n",
    "* Different start-end periods result in different Hedge Ratios and Spread Deviations.\n",
    "    * Longer timeframes (5yrs vs 30days) result in lower Hedge Ratios and Spread Deviations. It takes longer for the spread to converge.\n",
    "* It probably makes sense to hold on to the data for a given trading pair trade entry so that one can\n",
    "  continue to track the move to the originally calculate median (exit point), sticking to the original\n",
    "  trading plan. We add more data to the close columns and we calculate the spread and the current spread\n",
    "  the original Beta/Hedge Ratio, while the median (our exit point) stays the same.\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7fc409356f32a87a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T05:23:40.106368962Z",
     "start_time": "2026-01-08T05:23:39.982585460Z"
    }
   },
   "source": [
    "import sys\n",
    "from types import ModuleType, FunctionType\n",
    "from gc import get_referents\n",
    "\n",
    "# Helper function to get the size of an object (Curiosity)\n",
    "# Custom objects know their class.\n",
    "# Function objects seem to know way too much, including modules.\n",
    "# Exclude modules as well.\n",
    "BLACKLIST = type, ModuleType, FunctionType\n",
    "\n",
    "\n",
    "def getsize(obj):\n",
    "    \"\"\"sum size of object & members.\"\"\"\n",
    "    if isinstance(obj, BLACKLIST):\n",
    "        raise TypeError('getsize() does not take argument of type: '+ str(type(obj)))\n",
    "    seen_ids = set()\n",
    "    size = 0\n",
    "    objects = [obj]\n",
    "    while objects:\n",
    "        need_referents = []\n",
    "        for obj in objects:\n",
    "            if not isinstance(obj, BLACKLIST) and id(obj) not in seen_ids:\n",
    "                seen_ids.add(id(obj))\n",
    "                size += sys.getsizeof(obj)\n",
    "                need_referents.append(obj)\n",
    "        objects = get_referents(*need_referents)\n",
    "    return size \n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "afbfbce683d4a575",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T05:23:40.434755058Z",
     "start_time": "2026-01-08T05:23:40.209040781Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from decimal import Decimal\n",
    "from pandas_decimal import DecimaldDtype\n",
    "\n",
    "def get_trading_pair_spread(ppos: tuple, beta: Decimal = None, \n",
    "                            prev_days: int = None,\n",
    "                            start_period: int = None, end_period: int = None,\n",
    "                            start_date: str = None, end_date: str = None):\n",
    "    \n",
    "    # Create a DataFrame of the closing prices from the PPO[0 and 1].orig_data dataframes\n",
    "    closes1 = ppos[0].orig_data['Close'].astype(DecimaldDtype(5))\n",
    "    closes2 = ppos[1].orig_data['Close'].astype(DecimaldDtype(5))\n",
    "    # Make closes1 and closes2 the same length\n",
    "    min_len = min(len(closes1), len(closes2))\n",
    "    if prev_days is None:\n",
    "        prev_days = min_len\n",
    "    elif prev_days > min_len:\n",
    "        prev_days = min_len\n",
    "    if start_period is not None and end_period is not None:\n",
    "        # Gather closes based numeric index    \n",
    "        closes1 = closes1[start_period:end_period]\n",
    "        closes2 = closes2[start_period:end_period]\n",
    "    elif start_date is not None and end_date is not None:\n",
    "        # Gather closes based on the date index column\n",
    "        closes1 = closes1.loc[start_date:end_date]\n",
    "        closes2 = closes2.loc[start_date:end_date]\n",
    "    else:\n",
    "        # Default to the last prev_days    \n",
    "        closes1 = closes1.tail(prev_days)\n",
    "        closes2 = closes2.tail(prev_days)\n",
    "    df_closes = pd.DataFrame({'Stock_A': closes1, 'Stock_B': closes2})\n",
    "    # df_closes.replace([np.inf, -np.inf], None, inplace=True)\n",
    "    df_closes = df_closes.bfill().ffill()\n",
    "    try:\n",
    "        if beta is None:\n",
    "            # Perform OLS to find beta\n",
    "            X = df_closes['Stock_B']\n",
    "            X = sm.add_constant(X)  # Adds a constant term to the predictor\n",
    "            model = sm.OLS(df_closes['Stock_A'], X).fit()\n",
    "            beta = model.params['Stock_B']\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        beta = np.float32(1.0)\n",
    "        \n",
    "    # Detrend the closes\n",
    "    # closes1m = (closes1 - closes1.rolling(window=3)).mean()\n",
    "    closes1m = closes1.rolling(window=3).apply(lambda x: (x - x.mean()).mean())\n",
    "    # closes2m = (closes2 - closes2.rolling(window=3)).mean()\n",
    "    closes2m = closes2.rolling(window=3).apply(lambda x: (x - x.mean()).mean())\n",
    "    df_detrend = pd.DataFrame({'Stock_A': closes1m, 'Stock_B': closes2m})\n",
    "    df_detrend = df_detrend.bfill().ffill()\n",
    "    # Calculate the spread and its mean using the Hedge-Ratio beta \n",
    "    df_detrend['Spread'] = df_closes['Stock_A'] - beta * df_closes['Stock_B']\n",
    "    spread_mean = df_detrend['Spread'].mean()\n",
    "    # Create a line that is 1 standard deviation above from the spread-mean\n",
    "    df_detrend['Mean_1std_a'] = spread_mean + df_detrend['Spread'].std()\n",
    "    # Create a line that is 2 standard deviation above from the spread-mean\n",
    "    df_detrend['Mean_2std_a'] = spread_mean + 2 * df_detrend['Spread'].std()\n",
    "    # Create a line that is 1 standard deviation below from the spread-mean\n",
    "    df_detrend['Mean_1std_b'] = spread_mean - df_detrend['Spread'].std()\n",
    "    # Create a line that is 2 standard deviation below from the spread-mean\n",
    "    df_detrend['Mean_2std_b'] = spread_mean - 2 * df_detrend['Spread'].std()\n",
    "\n",
    "    return ppos, df_closes, df_detrend, spread_mean, beta \n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T05:23:40.780462964Z",
     "start_time": "2026-01-08T05:23:40.608962313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_annotation(sel):\n",
    "    x, y = sel.target\n",
    "    ind = sel.index\n",
    "    sel.annotation.set_text(f'{x:.0f}, {y:.0f}: {labels[ind]}')\n",
    "    \n",
    "def plot_spread(ppos: tuple, beta: Decimal = None, \n",
    "                prev_days: int = None,\n",
    "                title: str = None,   \n",
    "                spread_name: str = 'Spread',\n",
    "                spread_color: str = 'black',\n",
    "                start_period: int = None, end_period: int = None,\n",
    "                start_date: str = None, end_date: str = None):\n",
    "    \n",
    "    ppos, df_closes, df_detrend, spread_mean, beta = get_trading_pair_spread(ppos, beta, \n",
    "                                                                             prev_days, \n",
    "                                                                             start_period, end_period,\n",
    "                                                                             start_date, end_date)    \n",
    "    # Save the plot data to the PPO objects\n",
    "    pair = (ppos[0].ticker, ppos[1].ticker)\n",
    "    sp = spread_mean\n",
    "    cl = df_closes.copy(deep=True)\n",
    "    cl.reset_index(inplace=True)\n",
    "    cl = cl.to_json()\n",
    "    dc = df_detrend.copy(deep=True)\n",
    "    dc.reset_index(inplace=True)\n",
    "    dc = dc.to_json()\n",
    "    spread_analysis = {'pair': (ppos[0].ticker, ppos[1].ticker),\n",
    "                       'spread_mean': sp, \n",
    "                       'beta': beta,\n",
    "                       'closes': cl,\n",
    "                       'detrended_closes': dc\n",
    "                       }\n",
    "    ppos[0].spread_analysis[pair] = spread_analysis\n",
    "    ppos[1].spread_analysis[pair] = spread_analysis\n",
    "    \n",
    "    # Plot the spread with mean line\n",
    "    plt.plot(df_detrend['Spread'], marker='o', label=spread_name, color=spread_color)\n",
    "    plt.plot(df_detrend['Mean_2std_a'], label='2std_a', color='green')\n",
    "    plt.plot(df_detrend['Mean_1std_a'], label='1std_a', color='blue')\n",
    "    plt.plot(df_detrend['Mean_1std_b'], label='1std_b', color='blue')\n",
    "    plt.plot(df_detrend['Mean_2std_b'], label='2std_b', color='green')\n",
    "    plt.axhline(spread_mean, color='red', linestyle='--', label='Mean Spread')\n",
    "    plt.legend()\n",
    "    if title is None:\n",
    "        title = 'Spread Between Stock A and Stock B'\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel(spread_name)\n",
    "    # Enable x, y grid lines\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return plt, beta\n"
   ],
   "id": "e43f54eaba68617d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "c17310dc91021713",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T05:23:41.026177897Z",
     "start_time": "2026-01-08T05:23:40.781783970Z"
    }
   },
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# Import Libraries\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import sys\n",
    "import json\n",
    "import dill\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import berkeleydb as bdb\n",
    "\n",
    "from pricepredict import PricePredict\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "    \n",
    "# Use an Object Cache to reduce the prep time for creating and loading the PricePredict objects.\n",
    "if 'ObjCache' not in globals():\n",
    "    global ObjCache\n",
    "    ObjCache = bdb.btopen('ppo_cache.db', 'c')\n",
    "\n",
    "DirPPO = '../ppo/'\n",
    "def get_ppo(symbol: str, period: str):\n",
    "    \n",
    "    global ObjCache\n",
    "\n",
    "    # print(f'Type of ObjCache: {type(ObjCache)}')\n",
    "\n",
    "    ppo_name = symbol + '_' + period\n",
    "\n",
    "    if bytes(ppo_name, 'latin1') in ObjCache.keys():\n",
    "        print(f\"Using Cached PPO: {ppo_name}\")    \n",
    "        ppo = PricePredict.unserialize(ObjCache[bytes(ppo_name, 'latin1')])\n",
    "        return 'None', ppo\n",
    "    \n",
    "    file_name_starts_with = symbol + '_' + period\n",
    "    # Find all PPO files for the symbol in the PPO directory\n",
    "    ppo_files = [f for f in os.listdir(DirPPO) if f.startswith(file_name_starts_with) and f.endswith('.dilz')]\n",
    "    ppo = None\n",
    "    if len(ppo_files) > 0:\n",
    "        # Sort the files by date\n",
    "        ppo_files.sort()\n",
    "        # Get the latest PPO file\n",
    "        ppo_file = ppo_files[-1]\n",
    "        # Unpickle the PPO file using dilz\n",
    "        print(f\"Reading PPO File: {ppo_file}\")\n",
    "        with open(DirPPO + ppo_file, 'rb') as f:\n",
    "            f_obj = f.read()\n",
    "            ppo = PricePredict.unserialize(f_obj)\n",
    "            \n",
    "    if ppo is None:\n",
    "        ppo_file = ppo_name\n",
    "        print(f\"Creating PPO: {ppo_file}\")\n",
    "        ppo = PricePredict(symbol,\n",
    "                           model_dir='../models/',\n",
    "                           chart_dir='../charts/',\n",
    "                           preds_dir='../predictions/',\n",
    "                           period=period)\n",
    "        # Train the models on 5 yeas of data...\n",
    "        end_dt = datetime.now()\n",
    "        start_dt = end_dt - timedelta(days=5*400)\n",
    "        end_date = end_dt.strftime('%Y-%m-%d')\n",
    "        start_date = start_dt.strftime('%Y-%m-%d')\n",
    "        ppo.fetch_train_and_predict(ppo.ticker, \n",
    "                                    start_date, end_date, \n",
    "                                    start_date, end_date,\n",
    "                                    period=PricePredict.PeriodWeekly,\n",
    "                                    force_training=False,\n",
    "                                    use_curr_model=True,\n",
    "                                    save_model=False)\n",
    "        \n",
    "    # Cache the ppo\n",
    "    ObjCache[bytes(ppo_name, 'latin1')] = ppo.serialize_me()\n",
    "\n",
    "    return ppo_file, ppo\n",
    "\n",
    "def get_tradingpair_ppos(trading_pair: tuple):\n",
    "    tp1_weekly_ppo_file, tp1_weekly_ppo = get_ppo(trading_pair[0], PricePredict.PeriodWeekly)\n",
    "    tp1_daily_ppo_file, tp1_daily_ppo = get_ppo(trading_pair[0], PricePredict.PeriodDaily)\n",
    "    tp2_weekly_ppo_file, tp2_weekly_ppo = get_ppo(trading_pair[1], PricePredict.PeriodWeekly)\n",
    "    tp2_daily_ppo_file, tp2_daily_ppo = get_ppo(trading_pair[1], PricePredict.PeriodDaily)\n",
    "    # print(f'{trading_pair[0]} Weekly PPO: {tp1_weekly_ppo_file}[{tp1_weekly_ppo.period}] {tp1_weekly_ppo}:[{round(getsize(tp1_weekly_ppo)/1024/1024, 2)}]M')\n",
    "    # print(f'{trading_pair[0]} Daily PPO: {tp1_daily_ppo_file}[{tp1_daily_ppo.period}] {tp1_daily_ppo}:[{round(getsize(tp1_daily_ppo)/1024/1024, 2)}]M')\n",
    "    # print(f'{trading_pair[1]} Weekly PPO: {tp2_weekly_ppo_file}[{tp2_weekly_ppo.period}] {tp2_weekly_ppo}:[{round(getsize(tp2_weekly_ppo)/1024/1024, 2)}]M')\n",
    "    # print(f'{trading_pair[1]} Daily PPO: {tp2_daily_ppo_file}[{tp2_daily_ppo.period}] {tp2_daily_ppo}:[{round(getsize(tp2_daily_ppo)/1024/1024, 2)}]M')\n",
    "    return tp1_weekly_ppo, tp1_daily_ppo, tp2_weekly_ppo, tp2_daily_ppo    \n",
    "\n",
    "def check_ppo_orig_data(ppo: PricePredict, msg: str = None):\n",
    "    is_index_datetime = isinstance(ppo.orig_data.index, pd.DatetimeIndex)\n",
    "    is_date_in_index = 'Date' in ppo.orig_data.index.names    \n",
    "    if msg is not None and (is_date_in_index is True or is_index_datetime is True):\n",
    "        print(msg)    \n",
    "    if is_index_datetime is False:\n",
    "        print(f\"orig_data index is not a DatetimeIndex: {ppo.ticker} {ppo.period}\")\n",
    "    if is_date_in_index is False:\n",
    "        print(f\"orig_data index does not have a 'Date' column: {ppo.ticker} {ppo.period}\")\n",
    "\n",
    "def create_ppos(trading_pair: tuple):\n",
    "    global ObjCache\n",
    "    \n",
    "    model_dir = '../models/'\n",
    "    chart_dir = '../charts/'\n",
    "    preds_dir = '../predictions/'\n",
    "\n",
    "    tp1_weekly_ppo = PricePredict(ticker=trading_pair[0], period=PricePredict.PeriodWeekly,\n",
    "                                  model_dir=model_dir, chart_dir=chart_dir, preds_dir=preds_dir)\n",
    "    tp1_daily_ppo = PricePredict(ticker=trading_pair[0], period=PricePredict.PeriodDaily,\n",
    "                                 model_dir=model_dir, chart_dir=chart_dir, preds_dir=preds_dir)\n",
    "    tp2_weekly_ppo = PricePredict(ticker=trading_pair[1], period=PricePredict.PeriodWeekly,\n",
    "                                  model_dir=model_dir, chart_dir=chart_dir, preds_dir=preds_dir)\n",
    "    tp2_daily_ppo = PricePredict(ticker=trading_pair[1], period=PricePredict.PeriodDaily,\n",
    "                                 model_dir=model_dir, chart_dir=chart_dir, preds_dir=preds_dir)\n",
    "        \n",
    "    # Train the models on 5 yeas of data...\n",
    "    end_dt = datetime.now()\n",
    "    start_dt = end_dt - timedelta(days=5*400)\n",
    "    end_date = end_dt.strftime('%Y-%m-%d')\n",
    "    start_date = start_dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    print(f\"ObjCache: {ObjCache.keys()}\")\n",
    "    \n",
    "    # Load 2 years of data for the trading pair\n",
    "    ppo_name = trading_pair[0] + '_weekly_ppo'\n",
    "    if ppo_name not in ObjCache.keys():\n",
    "        tp1_weekly_ppo.fetch_train_and_predict(tp1_weekly_ppo.ticker, \n",
    "                                               start_date, end_date, \n",
    "                                               start_date, end_date,\n",
    "                                               period=PricePredict.PeriodWeekly,\n",
    "                                               force_training=False,\n",
    "                                               use_curr_model=True,\n",
    "                                               save_model=False)\n",
    "        check_ppo_orig_data(tp1_weekly_ppo, f\"After Yahoo Fetch {trading_pair[0]} Weekly PPO\")\n",
    "        ObjCache[ppo_name] = tp1_weekly_ppo.serialize_me()\n",
    "    else:\n",
    "        tp1_weekly_ppo = PricePredict.unserialize(ObjCache[ppo_name])\n",
    "        check_ppo_orig_data(tp1_weekly_ppo, f\"After loading from ObjCache {trading_pair[0]} Weekly PPO\")\n",
    "\n",
    "    ppo_name = trading_pair[0] + '_daily_ppo'\n",
    "    if ppo_name not in ObjCache.keys():\n",
    "        tp1_daily_ppo.fetch_train_and_predict(tp1_daily_ppo.ticker, \n",
    "                                               start_date, end_date, \n",
    "                                               start_date, end_date,\n",
    "                                               period=PricePredict.PeriodDaily,\n",
    "                                               force_training=False,\n",
    "                                               use_curr_model=True,\n",
    "                                               save_model=False)\n",
    "        check_ppo_orig_data(tp1_daily_ppo, f\"After Yahoo Fetch {trading_pair[0]} Daily PPO\")\n",
    "        ObjCache[ppo_name] = tp1_daily_ppo.serialize_me()\n",
    "    else:\n",
    "        tp1_daily_ppo = PricePredict.unserialize(ObjCache[ppo_name])\n",
    "        check_ppo_orig_data(tp1_daily_ppo, f\"After loading from ObjCache {trading_pair[0]} Daily PPO\")\n",
    "\n",
    "    ppo_name = trading_pair[1] + '_weekly_ppo'\n",
    "    if ppo_name not in ObjCache.keys():\n",
    "        tp2_weekly_ppo.fetch_train_and_predict(tp2_weekly_ppo.ticker,\n",
    "                                               start_date, end_date, \n",
    "                                               start_date, end_date,\n",
    "                                               period=PricePredict.PeriodWeekly,\n",
    "                                               force_training=False,\n",
    "                                               use_curr_model=True,\n",
    "                                               save_model=False)\n",
    "        check_ppo_orig_data(tp2_weekly_ppo, f\"After Yahoo Fetch {trading_pair[1]} Weekly PPO\")\n",
    "        ObjCache[ppo_name] = tp2_weekly_ppo.serialize_me()\n",
    "    else:\n",
    "        tp2_weekly_ppo = PricePredict.unserialize(ObjCache[ppo_name])\n",
    "        check_ppo_orig_data(tp2_weekly_ppo, f\"After loading from ObjCache {trading_pair[1]} Weekly PPO\")\n",
    "\n",
    "    ppo_name = trading_pair[1] + '_daily_ppo'\n",
    "    if ppo_name not in ObjCache.keys():\n",
    "        tp2_daily_ppo.fetch_train_and_predict(tp2_daily_ppo.ticker,\n",
    "                                               start_date, end_date, \n",
    "                                               start_date, end_date,\n",
    "                                               force_training=False,\n",
    "                                               use_curr_model=True,\n",
    "                                               save_model=False)\n",
    "        check_ppo_orig_data(tp2_daily_ppo, f\"After Yahoo Fetch {trading_pair[1]} Daily PPO\")\n",
    "        ObjCache[ppo_name] = tp2_daily_ppo.serialize_me()\n",
    "    else:\n",
    "        tp2_daily_ppo = PricePredict.unserialize(ObjCache[ppo_name])\n",
    "        check_ppo_orig_data(tp2_daily_ppo, f\"After loading from ObjCache {trading_pair[1]} Daily PPO\")\n",
    "\n",
    "    return tp1_weekly_ppo, tp1_daily_ppo, tp2_weekly_ppo, tp2_daily_ppo\n",
    "\n",
    "def determine_start_end_dates(start_date: str = None, period_len: int = None):\n",
    "    end_date = None\n",
    "    if start_date is None and period_len is None:\n",
    "        # Use the start_date and use today as the end_date\n",
    "        start_date = tp1_daily_ppo.orig_data.index[0].strftime('%Y-%m-%d')\n",
    "        end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    elif start_date is not None and  period_len is None:\n",
    "        # Use the start_date and get the end_date from the ppos' orig_data dataframe.    \n",
    "        start_date = start_date\n",
    "        end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    elif start_date is None and period_len is not None:\n",
    "        # Make the start_date period_len days before the today\n",
    "        end_dt = datetime.now()\n",
    "        end_date = end_dt.strftime('%Y-%m-%d')\n",
    "        start_dt = end_dt - timedelta(days=period_len)\n",
    "        start_date = start_dt.strftime('%Y-%m-%d')\n",
    "    elif start_date is not None and period_len is not None:\n",
    "        # Use the start_date and make end_date period_len days from the start_date    \n",
    "        start_date = start_date\n",
    "        end_dt = datetime.strptime(start_date, '%Y-%m-%d') + timedelta(days=period_len)\n",
    "        end_date = end_dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    return start_date, end_date\n",
    "    \n",
    "def analyze_trading_pair(trading_pair: tuple, start_date: str = None, period_len: int = None, mpl_plt: plt = None):\n",
    "\n",
    "    start_date, end_date = determine_start_end_dates(start_date=start_date, period_len=period_len)\n",
    "    \n",
    "    end_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    \n",
    "    # Allows the reuse of the matplotlib.pyplot plt object.\n",
    "    if mpl_plt is not None:\n",
    "        # Close the current plot so that it can be reused.\n",
    "        mpl_plt.close()\n",
    "\n",
    "    # Gather the Weekly and Daily PPOs for the trading pair from the ./ppo/ dir.\n",
    "    tp1_weekly_ppo, tp1_daily_ppo, tp2_weekly_ppo, tp2_daily_ppo = get_tradingpair_ppos(trading_pair)\n",
    "    \n",
    "    # Creates ppo objects and caches them to ObjCache.\n",
    "    # tp1_weekly_ppo, tp1_daily_ppo, tp2_weekly_ppo, tp2_daily_ppo = create_ppos(trading_pair)\n",
    "        \n",
    "    # Plot the median & spread of the trading pair given the daily PPOs)\n",
    "    # Plot the Weekly Spread using the Weekly calculated Beta\n",
    "    # plt, beta = plot_spread((tp1_weekly_ppo, tp2_weekly_ppo), \n",
    "    #                         title=f\"Weekly Spread [{trading_pair[0]} vs {trading_pair[1]}]\",\n",
    "    #                         spread_name='Weekly')\n",
    "    # print(f\"Weekly Hedge Ratio: {beta}\")\n",
    "\n",
    "    # # Plot the Daily Spread, Using the Weekly Beta\n",
    "    # plt, beta = plot_spread((tp1_daily_ppo, tp2_daily_ppo), beta, 60, \n",
    "    #             title=f\"Daily Spread [{trading_pair[0]} vs {trading_pair[1]}]\", \n",
    "    #             spread_name='Daily (Wkly Beta)', spread_color='grey')\n",
    "    # print(f\"Daily using Weekly Hedge Ratio: {beta}\")\n",
    "    # # Plot the Daily Spread, Using the Daily calculated Beta\n",
    "    # plt, beta = plot_spread((tp1_daily_ppo, tp2_daily_ppo), None, 60,\n",
    "    #                         title=f\"Daily Spread [{trading_pair[0]} vs {trading_pair[1]}]\", \n",
    "    #                         spread_name='Daily', spread_color='orange')\n",
    "    # print(f\"Daily Hedge Ratio: {beta}\")\n",
    "    # plt, beta = plot_spread((tp1_daily_ppo, tp2_daily_ppo),\n",
    "    #                         title=f\"Daily[1:37] Spread [{trading_pair[0]} vs {trading_pair[1]}]\", \n",
    "    #                         spread_name='Daily [1:37]', spread_color='orange',\n",
    "    #                         start_period=1, end_period=37)\n",
    "    # print(f\"Daily[1:37] Hedge Ratio {beta}\")\n",
    "    # plt, beta = plot_spread((tp1_daily_ppo, tp2_daily_ppo),\n",
    "    #                         title=f\"Daily[4/1/21 to 8/1/21] Spread [{trading_pair[0]} vs {trading_pair[1]}]\", \n",
    "    #                         spread_name='Daily [4/1/21 to 8/1/21]', spread_color='orange',\n",
    "    #                         start_date='4/1/2021', end_date='7/30/2021')\n",
    "    # print(f\"Daily[4/1/21 to 8/1/21] Hedge Ratio {beta}\")\n",
    "    \n",
    "    print(f\"Analyze Trading Pair Start Date: {start_date},  End Date: {end_date}\")\n",
    "    \n",
    "    plt, beta = plot_spread((tp1_daily_ppo, tp2_daily_ppo),\n",
    "                            title=f\"Daily[{start_date} to {end_date}] Spread [{trading_pair[0]} vs {trading_pair[1]}]\", \n",
    "                            spread_name='Daily [{start_date} to {end_date}]', spread_color='orange',\n",
    "                            start_date=start_date, end_date=end_date)\n",
    "    print(f\"Daily[{start_date} to {end_dt}] Hedge Ratio {beta}\")\n",
    "    \n",
    "    return plt\n"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pricepredict'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 16\u001B[39m\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mcopy\u001B[39;00m\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mberkeleydb\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mbdb\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpricepredict\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PricePredict\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mdatetime\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m datetime, timedelta\n\u001B[32m     20\u001B[39m \u001B[38;5;66;03m# Use an Object Cache to reduce the prep time for creating and loading the PricePredict objects.\u001B[39;00m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'pricepredict'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "getsize(ObjCache)",
   "id": "4d255cb05e6d7f84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Pair Trading Simulation\n",
    "\n",
    "* Given the current Trading Pair...\n",
    "    * From the beginning of the data...\n",
    "        * Perform the Spread Analysis on an 30day window, moving weekly through the data. \n",
    "            * When the spread goes above 2 standard deviations, open a pairs trade.\n",
    "              Be sure not to trade, trades that have already occurred. \n",
    "                * Immediatly move forward in time until the spread converges to the mean.\n",
    "                  Use the beta and append to the dataset (if needed) to calculate the spread \n",
    "                  and to keep the mean stable.\n",
    "                    * Calculate the profit/loss for each period. Are the draw-downs acceptable?\n",
    "                    * Hold on to the final profit/loss of the trade upon exit.\n",
    "    * Throw out open trades and calculate the total profit/loss."
   ],
   "id": "48362f759fd4d119"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def simulate_pairs_trading(ppos, start_date: str = None, period_len: int = 30):\n",
    "    \"\"\"\n",
    "    Simulate a Pairs Trading Strategy on the given Trading Pair PricePredict Objects.\n",
    "    - We will begin withe the start_date and move weekly through the data to the end_date\n",
    "      which is defined by period_len days from the start_date.\n",
    "    - First we look for a divergence in the spread of the two stocks that is 2 standard deviations\n",
    "      from the mean in either direction.\n",
    "    - Then we look for the spread to converge to the mean and close the trade.\n",
    "    - When we look for the convergence, we look for it 1 day at a time.\n",
    "    - We should fix the spread mean and beta for the trade.\n",
    "    - But we should also examine mean and betas as generate from the new data so we can do a study\n",
    "      of trades that do not converge. And understand what to look for with regard to strategies for\n",
    "      stopping-out or reorienting the based on the new beta to keep it in play.        \n",
    "    \"\"\"\n",
    "\n",
    "    start_date, end_date = determine_start_end_dates(start_date=start_date, period_len=period_len)\n",
    "    \n",
    "    # Get or create the required Trading Pair PPOs\n",
    "    tp1_weekly_ppo, tp1_daily_ppo, tp2_weekly_ppo, tp2_daily_ppo = get_tradingpair_ppos(ppos)\n",
    "\n",
    "    tp1_daily_ppo.fetch_data_yahoo(ticker=tp1_daily_ppo.ticker, date_start=start_date, date_end=end_date)\n",
    "    tp2_daily_ppo.fetch_data_yahoo(ticker=tp2_daily_ppo.ticker, date_start=start_date, date_end=end_date)\n",
    "\n",
    "    start_date1 = tp1_daily_ppo.orig_data.index[0]\n",
    "    end_date1 = tp1_daily_ppo.orig_data.index[-1]\n",
    "    start_date2 = tp2_daily_ppo.orig_data.index[0]\n",
    "    end_date2 = tp2_daily_ppo.orig_data.index[-1]\n",
    "        \n",
    "    # Align the start and end dates\n",
    "    start_date = min(start_date1, start_date2)\n",
    "    end_date = max(end_date1, end_date2)\n",
    "    \n",
    "    # Check the begin and end dates of the data...\n",
    "    print(f\"Start Date: {start_date},  End Date: {end_date}\")\n",
    "\n",
    "    # Create an iterable date range from start to end date\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='W')\n",
    "    \n",
    "    traded_dates = []\n",
    "    trade_counter = 0\n",
    "    last_trade_exit_dt = None\n",
    "    last_trade_exit_date = None\n",
    "    trade_date = None   # The date of a trade\n",
    "    exit_date = None\n",
    "    df_all_trades = pd.DataFrame()\n",
    "    df_all_convergence = pd.DataFrame()\n",
    "    in_trade = False\n",
    "    short_a_long_b = None\n",
    "    \n",
    "    # Each trade exists within the windows data range.\n",
    "    # This loop finds the start-date of a trade and the end-date of a trade.\n",
    "    # Start and end dates of trades should not overlap.\n",
    "    # Each cycle of the loop is a trade.\n",
    "    for win_date in date_range:\n",
    "        # print(f\"Window Date: {win_date}\")\n",
    "        # Calculate the spread for the 30 days prior to the win_date\n",
    "        win_date_start = win_date\n",
    "        if period_len is None:\n",
    "            period_len = 30\n",
    "        win_date_end = win_date_start + timedelta(days=period_len)\n",
    "        print(f\"Divergence Window Start Date: {win_date_start},  End Date: {win_date_end}\")\n",
    "        ppos, df_closes, df_detrend, spread_mean, beta = get_trading_pair_spread((tp1_daily_ppo, tp2_daily_ppo), start_date=win_date_start, end_date=win_date_end)    \n",
    "        trade_dt = None\n",
    "        \n",
    "        if last_trade_exit_date is None:\n",
    "            # Make the last trade exit date df_trend.index[0] - 1day\n",
    "            last_trade_exit_dt = df_detrend.index[0] - timedelta(days=1)\n",
    "            last_trade_exit_date = last_trade_exit_dt.strftime('%Y-%m-%d')\n",
    "            \n",
    "        # Get the dates when the spread is below 2 standard deviations\n",
    "        df_detrend['Spread'].bfill().ffill()\n",
    "        df_detrend['Mean_2std_a'].bfill().ffill()\n",
    "        dates_over_mean_2std = df_detrend[(df_detrend.index > last_trade_exit_date) & (df_detrend['Spread'] >= df_detrend['Mean_2std_a'])].copy()\n",
    "        # if in_trade is False and len(dates_over_mean_2std) > 0:\n",
    "        #     # Remove rows in dates_over_mean where Stock_A and Stock_B are 0\n",
    "        #     dates_over_mean_2std = dates_over_mean_2std[dates_over_mean_2std['Stock_A'] != 0]\n",
    "        #     dates_over_mean_2std = dates_over_mean_2std[dates_over_mean_2std['Stock_B'] != 0]\n",
    "        if in_trade is False and len(dates_over_mean_2std) > 0:\n",
    "            over_mean_trade_dt = dates_over_mean_2std.index[0]\n",
    "        \n",
    "        # Get the dates when the spread is below 2 standard deviations\n",
    "        dates_under_mean_2std = df_detrend[(df_detrend.index > last_trade_exit_date) & (df_detrend['Spread'] <= df_detrend['Mean_2std_b'])].copy()\n",
    "        # if in_trade is False and len(dates_under_mean_2std) > 0:\n",
    "        #     # Remove rows in dates_over_mean where Stock_A and Stock_B a\n",
    "        #     dates_under_mean_2std = dates_under_mean_2std[dates_under_mean_2std['Stock_A'] != 0]\n",
    "        #     dates_under_mean_2std = dates_under_mean_2std[dates_under_mean_2std['Stock_B'] != 0]\n",
    "        if in_trade is False and len(dates_under_mean_2std) > 0:\n",
    "            under_mean_trade_dt = dates_under_mean_2std.index[0]\n",
    "\n",
    "        if len(dates_over_mean_2std) > 0 and len(dates_under_mean_2std) > 0:\n",
    "            # Process the smaller date period    \n",
    "            if over_mean_trade_dt < under_mean_trade_dt:\n",
    "                if in_trade is False and len(dates_over_mean_2std) > 0:\n",
    "                    trade_dt = dates_over_mean_2std.index[0]\n",
    "                    in_trade = True    \n",
    "                    short_a_long_b = True\n",
    "                    print(f\"[{trade_dt}] Getting Into Trade[{trade_counter}]: Sort A Long B: {short_a_long_b}\")\n",
    "            elif over_mean_trade_dt > under_mean_trade_dt:\n",
    "                if in_trade is False and len(dates_under_mean_2std) > 0:\n",
    "                    trade_dt = dates_under_mean_2std.index[0]\n",
    "                    in_trade = True    \n",
    "                    short_a_long_b = False\n",
    "                    print(f\"[{trade_dt}] Getting Into Trade[{trade_counter}]: Sort A Long B: {short_a_long_b}\")\n",
    "        elif len(dates_over_mean_2std) > 0:\n",
    "                if in_trade is False and len(dates_over_mean_2std) > 0:\n",
    "                    trade_dt = dates_over_mean_2std.index[0]\n",
    "                    in_trade = True    \n",
    "                    short_a_long_b = True\n",
    "                    print(f\"[{trade_dt}] Getting Into Trade[{trade_counter}]: Sort A Long B: {short_a_long_b}\")\n",
    "        elif len(dates_under_mean_2std) > 0:            \n",
    "                if in_trade is False and len(dates_under_mean_2std) > 0:\n",
    "                    trade_dt = dates_under_mean_2std.index[0]\n",
    "                    in_trade = True    \n",
    "                    short_a_long_b = False\n",
    "                    print(f\"[{trade_dt}] Getting Into Trade[{trade_counter}]: Sort A Long B: {short_a_long_b}\")\n",
    "        \n",
    "        if trade_dt is not None:\n",
    "            trade_date = trade_dt.strftime('%Y-%m-%d')\n",
    "            \n",
    "        if (in_trade and\n",
    "                (trade_dt is not None and last_trade_exit_date is not None \n",
    "                 and  trade_dt <= last_trade_exit_dt)):\n",
    "            continue\n",
    "\n",
    "        saved_spread_mean = spread_mean\n",
    "        \n",
    "        # Go forward in time until the spread converges to the mean, using the same beta.\n",
    "        # Check if the current window has a future date where the spread converges to the mean.\n",
    "        # Get the first row where the spread is above the mean from dates_over_mean\n",
    "        \n",
    "        if short_a_long_b and len(dates_over_mean_2std) > 0:\n",
    "            # Get the first row where the spread is above the mean\n",
    "            df_trade = dates_over_mean_2std.iloc[0].copy()\n",
    "            # Get the first date where the spread is above the mean\n",
    "            trade_date = dates_over_mean_2std.index[0].strftime('%Y-%m-%d')\n",
    "            # Find when the spread converges to the mean\n",
    "            spread_converges = df_detrend[(df_detrend.index > trade_date) & (df_detrend['Spread'] <= saved_spread_mean)].copy()\n",
    "            if len(spread_converges) > 0:\n",
    "                exit_date = spread_converges.index[0].strftime('%Y-%m-%d')\n",
    "                print(f\"Short A Long B (Spread Converges): {trade_date} to {exit_date}\")\n",
    "            else:\n",
    "                trade_date = None    \n",
    "                exit_date = None\n",
    "        elif short_a_long_b is False and len(dates_under_mean_2std) > 0:\n",
    "            # Get the first row where the spread is under the mean\n",
    "            df_trade = dates_under_mean_2std.iloc[0].copy()\n",
    "            # Get the first date where the spread is above the mean\n",
    "            trade_date = dates_under_mean_2std.index[0].strftime('%Y-%m-%d')\n",
    "            spread_converges = df_detrend[(df_detrend.index > trade_date) & (df_detrend['Spread'] >= saved_spread_mean)].copy()\n",
    "            if len(spread_converges) > 0:\n",
    "                exit_date = spread_converges.index[0].strftime('%Y-%m-%d')\n",
    "                print(f\"Long A Short B (Spread Converges): {trade_date} to {exit_date}\")\n",
    "            else:\n",
    "                trade_date = None    \n",
    "                exit_date = None\n",
    "        \n",
    "        if trade_date is None:\n",
    "            print(f\"No more Tradeable Spreads found... Exiting\")    \n",
    "            break\n",
    "        # Make sure that we are paste the last trade exit date\n",
    "        if last_trade_exit_date is not None and trade_date <= last_trade_exit_date:\n",
    "            continue\n",
    "        \n",
    "        # Get the current actual price of the Stocks from the df_closes DataFrame\n",
    "        if trade_date in df_closes.index:\n",
    "            stock_a_entry = df_closes.loc[trade_date]['Stock_A']\n",
    "            stock_b_entry = df_closes.loc[trade_date]['Stock_B']\n",
    "        else:\n",
    "            # Actual stock prices are needed to calculate the trade\n",
    "            print(f\"Error: Could not get actual stock prices from df_closes Date: {trade_date} not in df_closes\")\n",
    "            break\n",
    "            \n",
    "        # if beta is < 0, reverse the trade\n",
    "        if beta < 0:\n",
    "            short_a_long_b = not short_a_long_b\n",
    "            \n",
    "        # Calculate the exit price of the Stocks\n",
    "        stock_a_exit = stock_b_entry * beta\n",
    "        stock_b_exit = stock_a_entry / beta\n",
    "        # Calculate the profit/loss of the trade\n",
    "        # We Short Stock_A and Long Stock_B\n",
    "        if short_a_long_b:\n",
    "            expected_profit = (stock_a_entry - stock_a_exit) + (stock_b_exit - stock_b_exit)\n",
    "        else:\n",
    "            expected_profit = (stock_a_exit - stock_a_entry) + (stock_b_entry - stock_b_exit)\n",
    "        # Calculate the quantity of Stock_A and Stock_B to trade\n",
    "        if beta > 0:\n",
    "            stock_a_quantity = 1\n",
    "            stock_b_quantity = beta * stock_a_quantity\n",
    "        else:\n",
    "            stock_b_quantity = 1\n",
    "            stock_a_quantity = beta * stock_b_quantity\n",
    "            \n",
    "        # Has this date been traded on before?\n",
    "        if (in_trade and trade_date not in traded_dates and exit_date is not None\n",
    "            and (last_trade_exit_date is None or trade_date > last_trade_exit_date)):\n",
    "\n",
    "            # Add stock_a_exit and stock_b_exit and expected_profit to the trade_entry DataFrame\n",
    "            # Calculate Stock Quantity to trade\n",
    "            df_trade['Trade_Entry'] = trade_date\n",
    "            df_trade['Spread_Mean'] = spread_mean\n",
    "            df_trade['Beta_HedgeRatio'] = beta\n",
    "            df_trade['ShortA_LongB'] = short_a_long_b\n",
    "            df_trade['Stock_A_Entry'] = stock_a_entry\n",
    "            df_trade['Stock_B_Entry'] = stock_b_entry\n",
    "            df_trade['Stock_A_Quantity'] = stock_a_quantity\n",
    "            df_trade['Stock_B_Quantity'] = stock_b_quantity\n",
    "            df_trade['Stock_A_Exit'] = stock_a_exit\n",
    "            df_trade['Stock_B_Exit'] = stock_b_exit\n",
    "            df_trade['Expected_Profit'] = expected_profit\n",
    "            df_trade['Trade_Counter'] = trade_counter\n",
    "            \n",
    "            # Perform the detrended spread analysis from the trade entry date to the end_dt\n",
    "            # simulating the trade as it evolves.\n",
    "            traded_dates.append(trade_date)\n",
    "            trade_dt = datetime.strptime(trade_date, '%Y-%m-%d')\n",
    "            end_dt = trade_dt + pd.Timedelta(days=1)\n",
    "            exit_dt = datetime.strptime(exit_date, '%Y-%m-%d')\n",
    "            short_a_conv = False\n",
    "            long_a_conv = False\n",
    "            while True:\n",
    "                end_dt_str = end_dt.strftime('%Y-%m-%d')\n",
    "                print(f\"Checking convergence between Start Date: {win_date_start},  End Date: {win_date_end} || [{end_dt_str}] ||\")\n",
    "                ppos, df_anl_closes, df_anl_detrend, spread_mean, beta = get_trading_pair_spread((tp1_daily_ppo, tp2_daily_ppo), beta=beta, start_date=win_date_start, end_date=end_dt_str)\n",
    "                ppos_n, df_anl_closes_n, df_anl_detrend_n, spread_mean_n, beta_n = get_trading_pair_spread((tp1_daily_ppo, tp2_daily_ppo), beta=None, start_date=win_date_start, end_date=end_dt_str)\n",
    "\n",
    "                # Check if the current window has a future date where the spread converges to the mean.\n",
    "                if short_a_long_b:\n",
    "                    short_a_conv = df_anl_detrend.iloc[-1]['Spread'] <= spread_mean\n",
    "                elif short_a_long_b is False:\n",
    "                    long_a_conv = df_anl_detrend.iloc[-1]['Spread'] >= spread_mean\n",
    "                    \n",
    "                if short_a_conv or long_a_conv:\n",
    "                    convergence = pd.DataFrame(df_anl_detrend.iloc[-1])\n",
    "                    print(f\"Found Convergence: {end_dt_str}\")    \n",
    "                    break\n",
    "\n",
    "                end_dt = end_dt + timedelta(days=1)\n",
    "            \n",
    "            # Grab the first row in Convergence\n",
    "            df_convergence = {}\n",
    "            if len(convergence) > 0 and in_trade:\n",
    "                # Get the date of the convergence\n",
    "                exit_dt = convergence.iloc[-1].index[0]\n",
    "                exit_date = exit_dt.strftime('%Y-%m-%d')\n",
    "                # Get the current actual price of the Stocks from the df_closes DataFrame\n",
    "                stock_a_exit = df_closes[df_closes.index == exit_dt]['Stock_A']\n",
    "                stock_b_exit = df_closes[df_closes.index == exit_dt]['Stock_B']\n",
    "                \n",
    "                # Add the saved_mean to the df_convergence DataFrame\n",
    "                df_convergence['Trade_Entry'] = trade_date\n",
    "                df_convergence['Trade_Exit'] = exit_date\n",
    "                df_convergence['Spread_Mean'] = saved_spread_mean\n",
    "                df_convergence['New_Spread_Mean'] = spread_mean\n",
    "                df_convergence['Beta_HedgeRatio'] = beta\n",
    "                df_convergence['ShortA_LongB'] = short_a_long_b\n",
    "                \n",
    "                # Add the exit prices to the df_convergence DataFrame\n",
    "                df_convergence['Stock_A_Exit'] = stock_a_exit\n",
    "                df_convergence['Stock_B_Exit'] = stock_b_exit\n",
    "                # Get entry value of Stock_A\n",
    "                entry_value_a = df_trade['Stock_A_Entry'] * df_trade['Stock_A_Quantity']\n",
    "                # Calculate exit value of Stock_B\n",
    "                entry_value_b = df_trade['Stock_B_Entry'] * df_trade['Stock_B_Quantity']\n",
    "                # Calculate the exit value of Stock_A\n",
    "                exit_value_a = df_convergence['Stock_A_Exit'] * df_trade['Stock_A_Quantity']\n",
    "                # Calculate the exit value of Stock_B\n",
    "                exit_value_b= df_convergence['Stock_B_Exit'] * df_trade['Stock_B_Quantity']\n",
    "                # Calculate the profit/loss of the trade\n",
    "                if short_a_long_b:\n",
    "                    profit_loss = (entry_value_a - exit_value_a) + (exit_value_b - entry_value_b)\n",
    "                else:\n",
    "                    profit_loss = (exit_value_a - entry_value_a) + (entry_value_b - exit_value_b)    \n",
    "                # Add the entry_value, exit_value, and profit_loss to the df_convergence DataFrame\n",
    "                df_convergence['Entry_Value'] = entry_value_a + entry_value_b\n",
    "                df_convergence['Exit_Value'] = exit_value_a + exit_value_b\n",
    "                df_convergence['Profit_Loss'] = profit_loss\n",
    "                df_convergence['Trade_Counter'] = trade_counter\n",
    "                \n",
    "                # Add the df_trade row to the df_all_trades DataFrame\n",
    "                if len(df_all_trades) == 0:\n",
    "                    df_all_trades = df_trade\n",
    "                else:\n",
    "                    df_all_trades = pd.concat([df_all_trades, df_trade], axis=1)\n",
    "                # Add the df_convergence row to the df_all_convergence DataFrame\n",
    "                if len(df_all_convergence) == 0:\n",
    "                    df_all_convergence = pd.Series(df_convergence)\n",
    "                else:\n",
    "                    df_all_convergence = pd.concat([df_all_convergence, pd.Series(df_convergence)], axis=1)\n",
    "                \n",
    "                print(f\"[{trade_date}] Trade Exit[{trade_counter}]: Short A Long B: {short_a_long_b}\")\n",
    "                trade_counter += 1\n",
    "                exit_date = None\n",
    "                last_trade_exit_date = trade_date\n",
    "                in_trade = False\n",
    "                short_a_long_b = None\n",
    "            pass\n",
    "        else:\n",
    "            # Trade never converges to the mean\n",
    "            df_trade['Converges'] = False\n",
    "            # TODO: Analyze for stop loss\n",
    "            print(f\"[{trade_date}] Trade Never Converges\")\n",
    "            trade_counter += 1\n",
    "            exit_date = None\n",
    "            in_trade = False\n",
    "            short_a_long_b = None\n",
    "            last_trade_exit_date = trade_date\n",
    "            traded_dates.append(trade_date)\n",
    "            continue\n",
    "            \n",
    "    final_trades = None\n",
    "    if len(df_all_trades) == 0:\n",
    "        print(f\"No Trades were made during the simulation\")\n",
    "    else:\n",
    "        print(f\"Total Trades: {trade_counter}\")\n",
    "        # Clean up the all_trades dataframe\n",
    "        df_all_trades = pd.DataFrame(df_all_trades.transpose())\n",
    "        excluded_columns = ['Stock_A', 'Stock_B', 'Trade_Entry', 'Trade_Exit', df_all_trades.columns[0]]\n",
    "        df_all_trades.loc[:, ~df_all_trades.columns.isin(excluded_columns)] = df_all_trades.loc[:, ~df_all_trades.columns.isin(excluded_columns)].astype(float)\n",
    "        # Clean up the all_convergence dataframe\n",
    "        df_all_convergence = pd.DataFrame(df_all_convergence.transpose())\n",
    "        excluded_columns = ['Stock_A', 'Stock_B', 'Trade_Entry', 'Trade_Exit', df_all_convergence.columns[0]]\n",
    "        df_all_convergence.loc[:, ~df_all_convergence.columns.isin(excluded_columns)] = df_all_convergence.loc[:, ~df_all_convergence.columns.isin(excluded_columns)].astype(float)\n",
    "    \n",
    "        # Merge the all_trades and all_convergence dataframes on the Trade_Counter column, resulting in just the unique columns between the two dataframes.\n",
    "        final_trades = pd.merge(df_all_trades, df_all_convergence, on='Trade_Counter', how='inner')\n",
    "        # Remove columns that end in _a\n",
    "        final_trades = final_trades.loc[:, ~final_trades.columns.str.endswith('_a')]\n",
    "        # Remove columns that end in _b\n",
    "        final_trades = final_trades.loc[:, ~final_trades.columns.str.endswith('_b')]\n",
    "        # Remove columns that end in _x\n",
    "        final_trades = final_trades.loc[:, ~final_trades.columns.str.endswith('_x')]\n",
    "        # Remove columns that end in _y\n",
    "        final_trades = final_trades.loc[:, ~final_trades.columns.str.endswith('_y')]\n",
    "        # Reindex the dataframe\n",
    "        final_trades.reindex(sorted(final_trades['Trade_Counter']), axis=1)\n",
    "\n",
    "    return final_trades\n",
    "\n",
    "\n",
    "trading_pair = ('ACN', 'ZM')\n",
    "trading_days = None\n",
    "# Plot the spread of the trading pair\n",
    "plt = analyze_trading_pair(trading_pair, start_date='2020-01-01', period_len=trading_days, mpl_plt=plt)\n",
    "\n",
    "# Simulate the pairs trading strategy\n",
    "df_all_trades = simulate_pairs_trading(trading_pair, start_date='2020-01-01', period_len=trading_days)\n"
   ],
   "id": "250aba3eb8598824",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "print(f\"Toal Profit/Loss: {df_all_trades['Profit_Loss'].sum()}\")\n",
    "df_all_trades\n"
   ],
   "id": "b3e1fa736db487a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_all_convergence['Profit_Loss'].sum()",
   "id": "5a960219342861d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Analyze PP Objects\n",
    "ppos = ('UPS', 'PTCT')\n",
    "# Get or create the required Trading Pair PPOs\n",
    "ppo1_w, ppo1_d, ppo2_w, ppo2_d = get_tradingpair_ppos(ppos)\n",
    "\n",
    "ObjCache.keys()\n"
   ],
   "id": "9e67f5f03d7de873",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
