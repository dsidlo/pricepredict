{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d05a19bb0dddc4ea",
   "metadata": {},
   "source": [
    "# Pair Trading Analysis\n",
    "  \n",
    "Given a pair of stocks that are Conintegrated, grab their PricePredict Objects from the\n",
    "ppo/ directory and plot a median/spread graph of the two stocks. This will allow us to see\n",
    "how the two stocks are moving relative to each other and if there are any opportunities to\n",
    "trade the spread between the two stocks.\n",
    "\n",
    "Run a simple trading simulation that uses a strategy of trading the 2 stocks at the same time\n",
    "as follows:\n",
    "* Opening a Pairs Trade...\n",
    "    * When the 2 stocks diverge and the stock that is overvalued is more than the historical standard deviation\n",
    "      from the mean (based on N most profitable moves) and the undervalued stock is more than the historical \n",
    "      standard deviation from the mean (etc.). \n",
    "        * Sell the overvalued stock and buy the undervalued stock.\n",
    "          Only do these trades if the prediction for the next day indicates that the overvalued stock\n",
    "          is going to go down and the undervalued stock is going to go up on on the current timeframe,\n",
    "          and on the next higher timeframe (weekly, given a daily trading timeframe).\n",
    "          Then buy/sell the stocks at the opening price of the next day.\n",
    "        * Use additional indicators that indicate a reversal in the spread (as needed). \n",
    "    * Do we trade from convergence?\n",
    "        * It does not make sense to trade from convergence, as it is difficult to determine which\n",
    "          stock to go long on and which stock to go short on.\n",
    "        * We should only trade from divergence, as we can determine which stock is overvalued and which\n",
    "          stock is undervalued. \n",
    "* Closing a Pairs Trade...\n",
    "    * Given an open Pairs Trade that started from a Spread Divergence... \n",
    "        * We wait for the spread to converge to the median and then close the trade.\n",
    "        * We then calculate the profit/loss of the trade and add it to the total profit/loss.\n",
    "* How to choose going long vs going short (one stock will be long and the other short)...\n",
    "    * The Spread calculation is essentially the difference between the two stocks. Stock_A - Stock_B.\n",
    "        * As Stock_A goes up and Stock_B goes down, the spread will increase (go up in the spread graph).\n",
    "        * As Stock_A goes down and Stock_B goes up, the spread will decrease (go down in the spread graph).    \n",
    "    * If the spread is above 2 standard deviations from the mean, we go short on Stock_A and long on Stock_B.\n",
    "    * If the spread is below 2 standard deviations from the mean, we go long on Stock_A and short on Stock_B.\n",
    "* How much to trade...\n",
    "    * We use the Hedge Ratio to determine how much of each stock to trade.\n",
    "        * The Hedge Ratio is the Beta from the OLS regression of Stock_A on Stock_B.\n",
    "    * The Hedge Ratio is the amount of Stock_B that is needed to hedge the risk of Stock_A.\n",
    "        * If the Hedge Ratio is 1.5, then we would trade 1.5 shares of Stock_B for every 1 share of Stock_A.\n",
    "        * If the Hedge Ratio is negative (-1.5), then for every 1 share of Stock_B, we would trade 1.5 shares of Stock_A.\n",
    "\n",
    "## Questions...\n",
    "\n",
    "* Which is a stronger indicator of Cointegration...\n",
    "    * Weekly or Daily?\n",
    "    * Both are useful much the way a weekly prediction indicates the longer term trend and a daily prediction\n",
    "      indicates the shorter term trend.\n",
    "\n",
    "## Insights...\n",
    "\n",
    "* Different start-end periods result in different Hedge Ratios and Spread Deviations.\n",
    "    * Longer timeframes (5yrs vs 30days) result in lower Hedge Ratios and Spread Deviations. It takes longer for the spread to converge.\n",
    "* It probably makes sense to hold on to the data for a given trading pair trade entry so that one can\n",
    "  continue to track the move to the originally calculate median (exit point), sticking to the original\n",
    "  trading plan. We add more data to the close columns and we calculate the spread and the current spread\n",
    "  the original Beta/Hedge Ratio, while the median (our exit point) stays the same.\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7fc409356f32a87a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T08:09:51.939098Z",
     "start_time": "2025-01-22T08:09:51.935526Z"
    }
   },
   "source": [
    "import sys\n",
    "from types import ModuleType, FunctionType\n",
    "from gc import get_referents\n",
    "\n",
    "# Helper function to get the size of an object (Curiosity)\n",
    "# Custom objects know their class.\n",
    "# Function objects seem to know way too much, including modules.\n",
    "# Exclude modules as well.\n",
    "BLACKLIST = type, ModuleType, FunctionType\n",
    "\n",
    "\n",
    "def getsize(obj):\n",
    "    \"\"\"sum size of object & members.\"\"\"\n",
    "    if isinstance(obj, BLACKLIST):\n",
    "        raise TypeError('getsize() does not take argument of type: '+ str(type(obj)))\n",
    "    seen_ids = set()\n",
    "    size = 0\n",
    "    objects = [obj]\n",
    "    while objects:\n",
    "        need_referents = []\n",
    "        for obj in objects:\n",
    "            if not isinstance(obj, BLACKLIST) and id(obj) not in seen_ids:\n",
    "                seen_ids.add(id(obj))\n",
    "                size += sys.getsizeof(obj)\n",
    "                need_referents.append(obj)\n",
    "        objects = get_referents(*need_referents)\n",
    "    return size \n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "afbfbce683d4a575",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T08:09:52.625896Z",
     "start_time": "2025-01-22T08:09:52.017626Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from decimal import Decimal\n",
    "from pandas_decimal import DecimaldDtype\n",
    "\n",
    "def get_trading_pair_spread(ppos: tuple, beta: Decimal = None, \n",
    "                            prev_days: int = None,\n",
    "                            start_period: int = None, end_period: int = None,\n",
    "                            start_date: str = None, end_date: str = None):\n",
    "    \n",
    "    # Create a DataFrame of the closing prices from the PPO[0 and 1].orig_data dataframes\n",
    "    closes1 = ppos[0].orig_data['Close'].astype(DecimaldDtype(5))\n",
    "    closes2 = ppos[1].orig_data['Close'].astype(DecimaldDtype(5))\n",
    "    # Make closes1 and closes2 the same length\n",
    "    min_len = min(len(closes1), len(closes2))\n",
    "    if prev_days is None:\n",
    "        prev_days = min_len\n",
    "    elif prev_days > min_len:\n",
    "        prev_days = min_len\n",
    "    if start_period is not None and end_period is not None:\n",
    "        # Gather closes based numeric index    \n",
    "        closes1 = closes1[start_period:end_period]\n",
    "        closes2 = closes2[start_period:end_period]\n",
    "    elif start_date is not None and end_date is not None:\n",
    "        # Gather closes based on the date index column\n",
    "        closes1 = closes1.loc[start_date:end_date]\n",
    "        closes2 = closes2.loc[start_date:end_date]\n",
    "    else:\n",
    "        # Default to the last prev_days    \n",
    "        closes1 = closes1.tail(prev_days)\n",
    "        closes2 = closes2.tail(prev_days)\n",
    "    df_closes = pd.DataFrame({'Stock_A': closes1, 'Stock_B': closes2})\n",
    "    # df_closes.replace([np.inf, -np.inf], None, inplace=True)\n",
    "    df_closes = df_closes.bfill().ffill()\n",
    "    try:\n",
    "        if beta is None:\n",
    "            # Perform OLS to find beta\n",
    "            X = df_closes['Stock_B']\n",
    "            X = sm.add_constant(X)  # Adds a constant term to the predictor\n",
    "            model = sm.OLS(df_closes['Stock_A'], X).fit()\n",
    "            beta = model.params['Stock_B']\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        beta = np.float32(1.0)\n",
    "        \n",
    "    # Detrend the closes\n",
    "    # closes1m = (closes1 - closes1.rolling(window=3)).mean()\n",
    "    closes1m = closes1.rolling(window=3).apply(lambda x: (x - x.mean()).mean())\n",
    "    # closes2m = (closes2 - closes2.rolling(window=3)).mean()\n",
    "    closes2m = closes2.rolling(window=3).apply(lambda x: (x - x.mean()).mean())\n",
    "    df_detrend = pd.DataFrame({'Stock_A': closes1m, 'Stock_B': closes2m})\n",
    "    df_detrend = df_detrend.bfill().ffill()\n",
    "    # Calculate the spread and its mean using the Hedge-Ratio beta \n",
    "    df_detrend['Spread'] = df_closes['Stock_A'] - beta * df_closes['Stock_B']\n",
    "    spread_mean = df_detrend['Spread'].mean()\n",
    "    # Create a line that is 1 standard deviation above from the spread-mean\n",
    "    df_detrend['Mean_1std_a'] = spread_mean + df_detrend['Spread'].std()\n",
    "    # Create a line that is 2 standard deviation above from the spread-mean\n",
    "    df_detrend['Mean_2std_a'] = spread_mean + 2 * df_detrend['Spread'].std()\n",
    "    # Create a line that is 1 standard deviation below from the spread-mean\n",
    "    df_detrend['Mean_1std_b'] = spread_mean - df_detrend['Spread'].std()\n",
    "    # Create a line that is 2 standard deviation below from the spread-mean\n",
    "    df_detrend['Mean_2std_b'] = spread_mean - 2 * df_detrend['Spread'].std()\n",
    "\n",
    "    return ppos, df_closes, df_detrend, spread_mean, beta \n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T08:09:52.837423Z",
     "start_time": "2025-01-22T08:09:52.626787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_annotation(sel):\n",
    "    x, y = sel.target\n",
    "    ind = sel.index\n",
    "    sel.annotation.set_text(f'{x:.0f}, {y:.0f}: {labels[ind]}')\n",
    "    \n",
    "def plot_spread(ppos: tuple, beta: Decimal = None, \n",
    "                prev_days: int = None,\n",
    "                title: str = None,   \n",
    "                spread_name: str = 'Spread',\n",
    "                spread_color: str = 'black',\n",
    "                start_period: int = None, end_period: int = None,\n",
    "                start_date: str = None, end_date: str = None):\n",
    "    \n",
    "    ppos, df_closes, df_detrend, spread_mean, beta = get_trading_pair_spread(ppos, beta, \n",
    "                                                                             prev_days, \n",
    "                                                                             start_period, end_period,\n",
    "                                                                             start_date, end_date)    \n",
    "    # Save the plot data to the PPO objects\n",
    "    pair = (ppos[0].ticker, ppos[1].ticker)\n",
    "    sp = spread_mean\n",
    "    cl = df_closes.copy(deep=True)\n",
    "    cl.reset_index(inplace=True)\n",
    "    cl = cl.to_json()\n",
    "    dc = df_detrend.copy(deep=True)\n",
    "    dc.reset_index(inplace=True)\n",
    "    dc = dc.to_json()\n",
    "    spread_analysis = {'pair': (ppos[0].ticker, ppos[1].ticker),\n",
    "                       'spread_mean': sp, \n",
    "                       'beta': beta,\n",
    "                       'closes': cl,\n",
    "                       'detrended_closes': dc\n",
    "                       }\n",
    "    ppos[0].spread_analysis[pair] = spread_analysis\n",
    "    ppos[1].spread_analysis[pair] = spread_analysis\n",
    "    \n",
    "    # Plot the spread with mean line\n",
    "    plt.plot(df_detrend['Spread'], marker='o', label=spread_name, color=spread_color)\n",
    "    plt.plot(df_detrend['Mean_2std_a'], label='2std_a', color='green')\n",
    "    plt.plot(df_detrend['Mean_1std_a'], label='1std_a', color='blue')\n",
    "    plt.plot(df_detrend['Mean_1std_b'], label='1std_b', color='blue')\n",
    "    plt.plot(df_detrend['Mean_2std_b'], label='2std_b', color='green')\n",
    "    plt.axhline(spread_mean, color='red', linestyle='--', label='Mean Spread')\n",
    "    plt.legend()\n",
    "    if title is None:\n",
    "        title = 'Spread Between Stock A and Stock B'\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel(spread_name)\n",
    "    # Enable x, y grid lines\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return plt, beta\n"
   ],
   "id": "e43f54eaba68617d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "c17310dc91021713",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T01:35:18.007254Z",
     "start_time": "2025-01-22T01:35:17.990194Z"
    }
   },
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# Import Libraries\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import sys\n",
    "import json\n",
    "import dill\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import berkeleydb as bdb\n",
    "\n",
    "from pricepredict import PricePredict\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "    \n",
    "# Use an Object Cache to reduce the prep time for creating and loading the PricePredict objects.\n",
    "if 'ObjCache' not in globals():\n",
    "    global ObjCache\n",
    "    ObjCache = bdb.btopen('ppo_cache.db', 'c')\n",
    "\n",
    "DirPPO = '../ppo/'\n",
    "def get_ppo(symbol: str, period: str):\n",
    "    \n",
    "    global ObjCache\n",
    "\n",
    "    # print(f'Type of ObjCache: {type(ObjCache)}')\n",
    "\n",
    "    ppo_name = symbol + '_' + period\n",
    "\n",
    "    if bytes(ppo_name, 'latin1') in ObjCache.keys():\n",
    "        print(f\"Using Cached PPO: {ppo_name}\")    \n",
    "        ppo = PricePredict.unserialize(ObjCache[bytes(ppo_name, 'latin1')])\n",
    "        return 'None', ppo\n",
    "    \n",
    "    file_name_starts_with = symbol + '_' + period\n",
    "    # Find all PPO files for the symbol in the PPO directory\n",
    "    ppo_files = [f for f in os.listdir(DirPPO) if f.startswith(file_name_starts_with) and f.endswith('.dilz')]\n",
    "    ppo = None\n",
    "    if len(ppo_files) > 0:\n",
    "        # Sort the files by date\n",
    "        ppo_files.sort()\n",
    "        # Get the latest PPO file\n",
    "        ppo_file = ppo_files[-1]\n",
    "        # Unpickle the PPO file using dilz\n",
    "        print(f\"Reading PPO File: {ppo_file}\")\n",
    "        with open(DirPPO + ppo_file, 'rb') as f:\n",
    "            f_obj = f.read()\n",
    "            ppo = PricePredict.unserialize(f_obj)\n",
    "            \n",
    "    if ppo is None:\n",
    "        ppo_file = ppo_name\n",
    "        print(f\"Creating PPO: {ppo_file}\")\n",
    "        ppo = PricePredict(symbol,\n",
    "                           model_dir='../models/',\n",
    "                           chart_dir='../charts/',\n",
    "                           preds_dir='../predictions/',\n",
    "                           period=period)\n",
    "        # Train the models on 5 yeas of data...\n",
    "        end_dt = datetime.now()\n",
    "        start_dt = end_dt - timedelta(days=5*400)\n",
    "        end_date = end_dt.strftime('%Y-%m-%d')\n",
    "        start_date = start_dt.strftime('%Y-%m-%d')\n",
    "        ppo.fetch_train_and_predict(ppo.ticker, \n",
    "                                    start_date, end_date, \n",
    "                                    start_date, end_date,\n",
    "                                    period=PricePredict.PeriodWeekly,\n",
    "                                    force_training=False,\n",
    "                                    use_curr_model=True,\n",
    "                                    save_model=False)\n",
    "        \n",
    "    # Cache the ppo\n",
    "    ObjCache[bytes(ppo_name, 'latin1')] = ppo.serialize_me()\n",
    "\n",
    "    return ppo_file, ppo\n",
    "\n",
    "def get_tradingpair_ppos(trading_pair: tuple):\n",
    "    tp1_weekly_ppo_file, tp1_weekly_ppo = get_ppo(trading_pair[0], PricePredict.PeriodWeekly)\n",
    "    tp1_daily_ppo_file, tp1_daily_ppo = get_ppo(trading_pair[0], PricePredict.PeriodDaily)\n",
    "    tp2_weekly_ppo_file, tp2_weekly_ppo = get_ppo(trading_pair[1], PricePredict.PeriodWeekly)\n",
    "    tp2_daily_ppo_file, tp2_daily_ppo = get_ppo(trading_pair[1], PricePredict.PeriodDaily)\n",
    "    # print(f'{trading_pair[0]} Weekly PPO: {tp1_weekly_ppo_file}[{tp1_weekly_ppo.period}] {tp1_weekly_ppo}:[{round(getsize(tp1_weekly_ppo)/1024/1024, 2)}]M')\n",
    "    # print(f'{trading_pair[0]} Daily PPO: {tp1_daily_ppo_file}[{tp1_daily_ppo.period}] {tp1_daily_ppo}:[{round(getsize(tp1_daily_ppo)/1024/1024, 2)}]M')\n",
    "    # print(f'{trading_pair[1]} Weekly PPO: {tp2_weekly_ppo_file}[{tp2_weekly_ppo.period}] {tp2_weekly_ppo}:[{round(getsize(tp2_weekly_ppo)/1024/1024, 2)}]M')\n",
    "    # print(f'{trading_pair[1]} Daily PPO: {tp2_daily_ppo_file}[{tp2_daily_ppo.period}] {tp2_daily_ppo}:[{round(getsize(tp2_daily_ppo)/1024/1024, 2)}]M')\n",
    "    return tp1_weekly_ppo, tp1_daily_ppo, tp2_weekly_ppo, tp2_daily_ppo    \n",
    "\n",
    "def check_ppo_orig_data(ppo: PricePredict, msg: str = None):\n",
    "    is_index_datetime = isinstance(ppo.orig_data.index, pd.DatetimeIndex)\n",
    "    is_date_in_index = 'Date' in ppo.orig_data.index.names    \n",
    "    if msg is not None and (is_date_in_index is True or is_index_datetime is True):\n",
    "        print(msg)    \n",
    "    if is_index_datetime is False:\n",
    "        print(f\"orig_data index is not a DatetimeIndex: {ppo.ticker} {ppo.period}\")\n",
    "    if is_date_in_index is False:\n",
    "        print(f\"orig_data index does not have a 'Date' column: {ppo.ticker} {ppo.period}\")\n",
    "\n",
    "def create_ppos(trading_pair: tuple):\n",
    "    global ObjCache\n",
    "    \n",
    "    model_dir = '../models/'\n",
    "    chart_dir = '../charts/'\n",
    "    preds_dir = '../predictions/'\n",
    "\n",
    "    tp1_weekly_ppo = PricePredict(ticker=trading_pair[0], period=PricePredict.PeriodWeekly,\n",
    "                                  model_dir=model_dir, chart_dir=chart_dir, preds_dir=preds_dir)\n",
    "    tp1_daily_ppo = PricePredict(ticker=trading_pair[0], period=PricePredict.PeriodDaily,\n",
    "                                 model_dir=model_dir, chart_dir=chart_dir, preds_dir=preds_dir)\n",
    "    tp2_weekly_ppo = PricePredict(ticker=trading_pair[1], period=PricePredict.PeriodWeekly,\n",
    "                                  model_dir=model_dir, chart_dir=chart_dir, preds_dir=preds_dir)\n",
    "    tp2_daily_ppo = PricePredict(ticker=trading_pair[1], period=PricePredict.PeriodDaily,\n",
    "                                 model_dir=model_dir, chart_dir=chart_dir, preds_dir=preds_dir)\n",
    "        \n",
    "    # Train the models on 5 yeas of data...\n",
    "    end_dt = datetime.now()\n",
    "    start_dt = end_dt - timedelta(days=5*400)\n",
    "    end_date = end_dt.strftime('%Y-%m-%d')\n",
    "    start_date = start_dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    print(f\"ObjCache: {ObjCache.keys()}\")\n",
    "    \n",
    "    # Load 2 years of data for the trading pair\n",
    "    ppo_name = trading_pair[0] + '_weekly_ppo'\n",
    "    if ppo_name not in ObjCache.keys():\n",
    "        tp1_weekly_ppo.fetch_train_and_predict(tp1_weekly_ppo.ticker, \n",
    "                                               start_date, end_date, \n",
    "                                               start_date, end_date,\n",
    "                                               period=PricePredict.PeriodWeekly,\n",
    "                                               force_training=False,\n",
    "                                               use_curr_model=True,\n",
    "                                               save_model=False)\n",
    "        check_ppo_orig_data(tp1_weekly_ppo, f\"After Yahoo Fetch {trading_pair[0]} Weekly PPO\")\n",
    "        ObjCache[ppo_name] = tp1_weekly_ppo.serialize_me()\n",
    "    else:\n",
    "        tp1_weekly_ppo = PricePredict.unserialize(ObjCache[ppo_name])\n",
    "        check_ppo_orig_data(tp1_weekly_ppo, f\"After loading from ObjCache {trading_pair[0]} Weekly PPO\")\n",
    "\n",
    "    ppo_name = trading_pair[0] + '_daily_ppo'\n",
    "    if ppo_name not in ObjCache.keys():\n",
    "        tp1_daily_ppo.fetch_train_and_predict(tp1_daily_ppo.ticker, \n",
    "                                               start_date, end_date, \n",
    "                                               start_date, end_date,\n",
    "                                               period=PricePredict.PeriodDaily,\n",
    "                                               force_training=False,\n",
    "                                               use_curr_model=True,\n",
    "                                               save_model=False)\n",
    "        check_ppo_orig_data(tp1_daily_ppo, f\"After Yahoo Fetch {trading_pair[0]} Daily PPO\")\n",
    "        ObjCache[ppo_name] = tp1_daily_ppo.serialize_me()\n",
    "    else:\n",
    "        tp1_daily_ppo = PricePredict.unserialize(ObjCache[ppo_name])\n",
    "        check_ppo_orig_data(tp1_daily_ppo, f\"After loading from ObjCache {trading_pair[0]} Daily PPO\")\n",
    "\n",
    "    ppo_name = trading_pair[1] + '_weekly_ppo'\n",
    "    if ppo_name not in ObjCache.keys():\n",
    "        tp2_weekly_ppo.fetch_train_and_predict(tp2_weekly_ppo.ticker,\n",
    "                                               start_date, end_date, \n",
    "                                               start_date, end_date,\n",
    "                                               period=PricePredict.PeriodWeekly,\n",
    "                                               force_training=False,\n",
    "                                               use_curr_model=True,\n",
    "                                               save_model=False)\n",
    "        check_ppo_orig_data(tp2_weekly_ppo, f\"After Yahoo Fetch {trading_pair[1]} Weekly PPO\")\n",
    "        ObjCache[ppo_name] = tp2_weekly_ppo.serialize_me()\n",
    "    else:\n",
    "        tp2_weekly_ppo = PricePredict.unserialize(ObjCache[ppo_name])\n",
    "        check_ppo_orig_data(tp2_weekly_ppo, f\"After loading from ObjCache {trading_pair[1]} Weekly PPO\")\n",
    "\n",
    "    ppo_name = trading_pair[1] + '_daily_ppo'\n",
    "    if ppo_name not in ObjCache.keys():\n",
    "        tp2_daily_ppo.fetch_train_and_predict(tp2_daily_ppo.ticker,\n",
    "                                               start_date, end_date, \n",
    "                                               start_date, end_date,\n",
    "                                               force_training=False,\n",
    "                                               use_curr_model=True,\n",
    "                                               save_model=False)\n",
    "        check_ppo_orig_data(tp2_daily_ppo, f\"After Yahoo Fetch {trading_pair[1]} Daily PPO\")\n",
    "        ObjCache[ppo_name] = tp2_daily_ppo.serialize_me()\n",
    "    else:\n",
    "        tp2_daily_ppo = PricePredict.unserialize(ObjCache[ppo_name])\n",
    "        check_ppo_orig_data(tp2_daily_ppo, f\"After loading from ObjCache {trading_pair[1]} Daily PPO\")\n",
    "\n",
    "    return tp1_weekly_ppo, tp1_daily_ppo, tp2_weekly_ppo, tp2_daily_ppo\n",
    "\n",
    "def determine_start_end_dates(start_date: str = None, period_len: int = None):\n",
    "    end_date = None\n",
    "    if start_date is None and period_len is None:\n",
    "        # Use the start_date and use today as the end_date\n",
    "        start_date = tp1_daily_ppo.orig_data.index[0].strftime('%Y-%m-%d')\n",
    "        end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    elif start_date is not None and  period_len is None:\n",
    "        # Use the start_date and get the end_date from the ppos' orig_data dataframe.    \n",
    "        start_date = start_date\n",
    "        end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    elif start_date is None and period_len is not None:\n",
    "        # Make the start_date period_len days before the today\n",
    "        end_dt = datetime.now()\n",
    "        end_date = end_dt.strftime('%Y-%m-%d')\n",
    "        start_dt = end_dt - timedelta(days=period_len)\n",
    "        start_date = start_dt.strftime('%Y-%m-%d')\n",
    "    elif start_date is not None and period_len is not None:\n",
    "        # Use the start_date and make end_date period_len days from the start_date    \n",
    "        start_date = start_date\n",
    "        end_dt = datetime.strptime(start_date, '%Y-%m-%d') + timedelta(days=period_len)\n",
    "        end_date = end_dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    return start_date, end_date\n",
    "    \n",
    "def analyze_trading_pair(trading_pair: tuple, start_date: str = None, period_len: int = None, mpl_plt: plt = None):\n",
    "\n",
    "    start_date, end_date = determine_start_end_dates(start_date=start_date, period_len=period_len)\n",
    "    \n",
    "    end_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    \n",
    "    # Allows the reuse of the matplotlib.pyplot plt object.\n",
    "    if mpl_plt is not None:\n",
    "        # Close the current plot so that it can be reused.\n",
    "        mpl_plt.close()\n",
    "\n",
    "    # Gather the Weekly and Daily PPOs for the trading pair from the ./ppo/ dir.\n",
    "    tp1_weekly_ppo, tp1_daily_ppo, tp2_weekly_ppo, tp2_daily_ppo = get_tradingpair_ppos(trading_pair)\n",
    "    \n",
    "    # Creates ppo objects and caches them to ObjCache.\n",
    "    # tp1_weekly_ppo, tp1_daily_ppo, tp2_weekly_ppo, tp2_daily_ppo = create_ppos(trading_pair)\n",
    "        \n",
    "    # Plot the median & spread of the trading pair given the daily PPOs)\n",
    "    # Plot the Weekly Spread using the Weekly calculated Beta\n",
    "    # plt, beta = plot_spread((tp1_weekly_ppo, tp2_weekly_ppo), \n",
    "    #                         title=f\"Weekly Spread [{trading_pair[0]} vs {trading_pair[1]}]\",\n",
    "    #                         spread_name='Weekly')\n",
    "    # print(f\"Weekly Hedge Ratio: {beta}\")\n",
    "\n",
    "    # # Plot the Daily Spread, Using the Weekly Beta\n",
    "    # plt, beta = plot_spread((tp1_daily_ppo, tp2_daily_ppo), beta, 60, \n",
    "    #             title=f\"Daily Spread [{trading_pair[0]} vs {trading_pair[1]}]\", \n",
    "    #             spread_name='Daily (Wkly Beta)', spread_color='grey')\n",
    "    # print(f\"Daily using Weekly Hedge Ratio: {beta}\")\n",
    "    # # Plot the Daily Spread, Using the Daily calculated Beta\n",
    "    # plt, beta = plot_spread((tp1_daily_ppo, tp2_daily_ppo), None, 60,\n",
    "    #                         title=f\"Daily Spread [{trading_pair[0]} vs {trading_pair[1]}]\", \n",
    "    #                         spread_name='Daily', spread_color='orange')\n",
    "    # print(f\"Daily Hedge Ratio: {beta}\")\n",
    "    # plt, beta = plot_spread((tp1_daily_ppo, tp2_daily_ppo),\n",
    "    #                         title=f\"Daily[1:37] Spread [{trading_pair[0]} vs {trading_pair[1]}]\", \n",
    "    #                         spread_name='Daily [1:37]', spread_color='orange',\n",
    "    #                         start_period=1, end_period=37)\n",
    "    # print(f\"Daily[1:37] Hedge Ratio {beta}\")\n",
    "    # plt, beta = plot_spread((tp1_daily_ppo, tp2_daily_ppo),\n",
    "    #                         title=f\"Daily[4/1/21 to 8/1/21] Spread [{trading_pair[0]} vs {trading_pair[1]}]\", \n",
    "    #                         spread_name='Daily [4/1/21 to 8/1/21]', spread_color='orange',\n",
    "    #                         start_date='4/1/2021', end_date='7/30/2021')\n",
    "    # print(f\"Daily[4/1/21 to 8/1/21] Hedge Ratio {beta}\")\n",
    "    \n",
    "    print(f\"Analyze Trading Pair Start Date: {start_date},  End Date: {end_date}\")\n",
    "    \n",
    "    plt, beta = plot_spread((tp1_daily_ppo, tp2_daily_ppo),\n",
    "                            title=f\"Daily[{start_date} to {end_date}] Spread [{trading_pair[0]} vs {trading_pair[1]}]\", \n",
    "                            spread_name='Daily [{start_date} to {end_date}]', spread_color='orange',\n",
    "                            start_date=start_date, end_date=end_date)\n",
    "    print(f\"Daily[{start_date} to {end_dt}] Hedge Ratio {beta}\")\n",
    "    \n",
    "    return plt\n"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T01:35:18.013680Z",
     "start_time": "2025-01-22T01:35:18.008083Z"
    }
   },
   "cell_type": "code",
   "source": "getsize(ObjCache)",
   "id": "4d255cb05e6d7f84",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Pair Trading Simulation\n",
    "\n",
    "* Given the current Trading Pair...\n",
    "    * From the beginning of the data...\n",
    "        * Perform the Spread Analysis on an 30day window, moving weekly through the data. \n",
    "            * When the spread goes above 2 standard deviations, open a pairs trade.\n",
    "              Be sure not to trade, trades that have already occurred. \n",
    "                * Immediatly move forward in time until the spread converges to the mean.\n",
    "                  Use the beta and append to the dataset (if needed) to calculate the spread \n",
    "                  and to keep the mean stable.\n",
    "                    * Calculate the profit/loss for each period. Are the draw-downs acceptable?\n",
    "                    * Hold on to the final profit/loss of the trade upon exit.\n",
    "    * Throw out open trades and calculate the total profit/loss."
   ],
   "id": "48362f759fd4d119"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T01:35:20.728772Z",
     "start_time": "2025-01-22T01:35:19.876963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def simulate_pairs_trading(ppos, start_date: str = None, period_len: int = 30):\n",
    "    \"\"\"\n",
    "    Simulate a Pairs Trading Strategy on the given Trading Pair PricePredict Objects.\n",
    "    - We will begin withe the start_date and move weekly through the data to the end_date\n",
    "      which is defined by period_len days from the start_date.\n",
    "    - First we look for a divergence in the spread of the two stocks that is 2 standard deviations\n",
    "      from the mean in either direction.\n",
    "    - Then we look for the spread to converge to the mean and close the trade.\n",
    "    - When we look for the convergence, we look for it 1 day at a time.\n",
    "    - We should fix the spread mean and beta for the trade.\n",
    "    - But we should also examine mean and betas as generate from the new data so we can do a study\n",
    "      of trades that do not converge. And understand what to look for with regard to strategies for\n",
    "      stopping-out or reorienting the based on the new beta to keep it in play.        \n",
    "    \"\"\"\n",
    "\n",
    "    start_date, end_date = determine_start_end_dates(start_date=start_date, period_len=period_len)\n",
    "    \n",
    "    # Get or create the required Trading Pair PPOs\n",
    "    tp1_weekly_ppo, tp1_daily_ppo, tp2_weekly_ppo, tp2_daily_ppo = get_tradingpair_ppos(ppos)\n",
    "\n",
    "    tp1_daily_ppo.fetch_data_yahoo(ticker=tp1_daily_ppo.ticker, date_start=start_date, date_end=end_date)\n",
    "    tp2_daily_ppo.fetch_data_yahoo(ticker=tp2_daily_ppo.ticker, date_start=start_date, date_end=end_date)\n",
    "\n",
    "    start_date1 = tp1_daily_ppo.orig_data.index[0]\n",
    "    end_date1 = tp1_daily_ppo.orig_data.index[-1]\n",
    "    start_date2 = tp2_daily_ppo.orig_data.index[0]\n",
    "    end_date2 = tp2_daily_ppo.orig_data.index[-1]\n",
    "        \n",
    "    # Align the start and end dates\n",
    "    start_date = min(start_date1, start_date2)\n",
    "    end_date = max(end_date1, end_date2)\n",
    "    \n",
    "    # Check the begin and end dates of the data...\n",
    "    print(f\"Start Date: {start_date},  End Date: {end_date}\")\n",
    "\n",
    "    # Create an iterable date range from start to end date\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='W')\n",
    "    \n",
    "    traded_dates = []\n",
    "    trade_counter = 0\n",
    "    last_trade_exit_dt = None\n",
    "    last_trade_exit_date = None\n",
    "    trade_date = None   # The date of a trade\n",
    "    exit_date = None\n",
    "    df_all_trades = pd.DataFrame()\n",
    "    df_all_convergence = pd.DataFrame()\n",
    "    in_trade = False\n",
    "    short_a_long_b = None\n",
    "    \n",
    "    # Each trade exists within the windows data range.\n",
    "    # This loop finds the start-date of a trade and the end-date of a trade.\n",
    "    # Start and end dates of trades should not overlap.\n",
    "    # Each cycle of the loop is a trade.\n",
    "    for win_date in date_range:\n",
    "        # print(f\"Window Date: {win_date}\")\n",
    "        # Calculate the spread for the 30 days prior to the win_date\n",
    "        win_date_start = win_date\n",
    "        if period_len is None:\n",
    "            period_len = 30\n",
    "        win_date_end = win_date_start + timedelta(days=period_len)\n",
    "        print(f\"Divergence Window Start Date: {win_date_start},  End Date: {win_date_end}\")\n",
    "        ppos, df_closes, df_detrend, spread_mean, beta = get_trading_pair_spread((tp1_daily_ppo, tp2_daily_ppo), start_date=win_date_start, end_date=win_date_end)    \n",
    "        trade_dt = None\n",
    "        \n",
    "        if last_trade_exit_date is None:\n",
    "            # Make the last trade exit date df_trend.index[0] - 1day\n",
    "            last_trade_exit_dt = df_detrend.index[0] - timedelta(days=1)\n",
    "            last_trade_exit_date = last_trade_exit_dt.strftime('%Y-%m-%d')\n",
    "            \n",
    "        # Get the dates when the spread is below 2 standard deviations\n",
    "        df_detrend['Spread'].bfill().ffill()\n",
    "        df_detrend['Mean_2std_a'].bfill().ffill()\n",
    "        dates_over_mean_2std = df_detrend[(df_detrend.index > last_trade_exit_date) & (df_detrend['Spread'] >= df_detrend['Mean_2std_a'])].copy()\n",
    "        # if in_trade is False and len(dates_over_mean_2std) > 0:\n",
    "        #     # Remove rows in dates_over_mean where Stock_A and Stock_B are 0\n",
    "        #     dates_over_mean_2std = dates_over_mean_2std[dates_over_mean_2std['Stock_A'] != 0]\n",
    "        #     dates_over_mean_2std = dates_over_mean_2std[dates_over_mean_2std['Stock_B'] != 0]\n",
    "        if in_trade is False and len(dates_over_mean_2std) > 0:\n",
    "            over_mean_trade_dt = dates_over_mean_2std.index[0]\n",
    "        \n",
    "        # Get the dates when the spread is below 2 standard deviations\n",
    "        dates_under_mean_2std = df_detrend[(df_detrend.index > last_trade_exit_date) & (df_detrend['Spread'] <= df_detrend['Mean_2std_b'])].copy()\n",
    "        # if in_trade is False and len(dates_under_mean_2std) > 0:\n",
    "        #     # Remove rows in dates_over_mean where Stock_A and Stock_B a\n",
    "        #     dates_under_mean_2std = dates_under_mean_2std[dates_under_mean_2std['Stock_A'] != 0]\n",
    "        #     dates_under_mean_2std = dates_under_mean_2std[dates_under_mean_2std['Stock_B'] != 0]\n",
    "        if in_trade is False and len(dates_under_mean_2std) > 0:\n",
    "            under_mean_trade_dt = dates_under_mean_2std.index[0]\n",
    "\n",
    "        if len(dates_over_mean_2std) > 0 and len(dates_under_mean_2std) > 0:\n",
    "            # Process the smaller date period    \n",
    "            if over_mean_trade_dt < under_mean_trade_dt:\n",
    "                if in_trade is False and len(dates_over_mean_2std) > 0:\n",
    "                    trade_dt = dates_over_mean_2std.index[0]\n",
    "                    in_trade = True    \n",
    "                    short_a_long_b = True\n",
    "                    print(f\"[{trade_dt}] Getting Into Trade[{trade_counter}]: Sort A Long B: {short_a_long_b}\")\n",
    "            elif over_mean_trade_dt > under_mean_trade_dt:\n",
    "                if in_trade is False and len(dates_under_mean_2std) > 0:\n",
    "                    trade_dt = dates_under_mean_2std.index[0]\n",
    "                    in_trade = True    \n",
    "                    short_a_long_b = False\n",
    "                    print(f\"[{trade_dt}] Getting Into Trade[{trade_counter}]: Sort A Long B: {short_a_long_b}\")\n",
    "        elif len(dates_over_mean_2std) > 0:\n",
    "                if in_trade is False and len(dates_over_mean_2std) > 0:\n",
    "                    trade_dt = dates_over_mean_2std.index[0]\n",
    "                    in_trade = True    \n",
    "                    short_a_long_b = True\n",
    "                    print(f\"[{trade_dt}] Getting Into Trade[{trade_counter}]: Sort A Long B: {short_a_long_b}\")\n",
    "        elif len(dates_under_mean_2std) > 0:            \n",
    "                if in_trade is False and len(dates_under_mean_2std) > 0:\n",
    "                    trade_dt = dates_under_mean_2std.index[0]\n",
    "                    in_trade = True    \n",
    "                    short_a_long_b = False\n",
    "                    print(f\"[{trade_dt}] Getting Into Trade[{trade_counter}]: Sort A Long B: {short_a_long_b}\")\n",
    "        \n",
    "        if trade_dt is not None:\n",
    "            trade_date = trade_dt.strftime('%Y-%m-%d')\n",
    "            \n",
    "        if (in_trade and\n",
    "                (trade_dt is not None and last_trade_exit_date is not None \n",
    "                 and  trade_dt <= last_trade_exit_dt)):\n",
    "            continue\n",
    "\n",
    "        saved_spread_mean = spread_mean\n",
    "        \n",
    "        # Go forward in time until the spread converges to the mean, using the same beta.\n",
    "        # Check if the current window has a future date where the spread converges to the mean.\n",
    "        # Get the first row where the spread is above the mean from dates_over_mean\n",
    "        \n",
    "        if short_a_long_b and len(dates_over_mean_2std) > 0:\n",
    "            # Get the first row where the spread is above the mean\n",
    "            df_trade = dates_over_mean_2std.iloc[0].copy()\n",
    "            # Get the first date where the spread is above the mean\n",
    "            trade_date = dates_over_mean_2std.index[0].strftime('%Y-%m-%d')\n",
    "            # Find when the spread converges to the mean\n",
    "            spread_converges = df_detrend[(df_detrend.index > trade_date) & (df_detrend['Spread'] <= saved_spread_mean)].copy()\n",
    "            if len(spread_converges) > 0:\n",
    "                exit_date = spread_converges.index[0].strftime('%Y-%m-%d')\n",
    "                print(f\"Short A Long B (Spread Converges): {trade_date} to {exit_date}\")\n",
    "            else:\n",
    "                trade_date = None    \n",
    "                exit_date = None\n",
    "        elif short_a_long_b is False and len(dates_under_mean_2std) > 0:\n",
    "            # Get the first row where the spread is under the mean\n",
    "            df_trade = dates_under_mean_2std.iloc[0].copy()\n",
    "            # Get the first date where the spread is above the mean\n",
    "            trade_date = dates_under_mean_2std.index[0].strftime('%Y-%m-%d')\n",
    "            spread_converges = df_detrend[(df_detrend.index > trade_date) & (df_detrend['Spread'] >= saved_spread_mean)].copy()\n",
    "            if len(spread_converges) > 0:\n",
    "                exit_date = spread_converges.index[0].strftime('%Y-%m-%d')\n",
    "                print(f\"Long A Short B (Spread Converges): {trade_date} to {exit_date}\")\n",
    "            else:\n",
    "                trade_date = None    \n",
    "                exit_date = None\n",
    "        \n",
    "        if trade_date is None:\n",
    "            print(f\"No more Tradeable Spreads found... Exiting\")    \n",
    "            break\n",
    "        # Make sure that we are paste the last trade exit date\n",
    "        if last_trade_exit_date is not None and trade_date <= last_trade_exit_date:\n",
    "            continue\n",
    "        \n",
    "        # Get the current actual price of the Stocks from the df_closes DataFrame\n",
    "        if trade_date in df_closes.index:\n",
    "            stock_a_entry = df_closes.loc[trade_date]['Stock_A']\n",
    "            stock_b_entry = df_closes.loc[trade_date]['Stock_B']\n",
    "        else:\n",
    "            # Actual stock prices are needed to calculate the trade\n",
    "            print(f\"Error: Could not get actual stock prices from df_closes Date: {trade_date} not in df_closes\")\n",
    "            break\n",
    "            \n",
    "        # if beta is < 0, reverse the trade\n",
    "        if beta < 0:\n",
    "            short_a_long_b = not short_a_long_b\n",
    "            \n",
    "        # Calculate the exit price of the Stocks\n",
    "        stock_a_exit = stock_b_entry * beta\n",
    "        stock_b_exit = stock_a_entry / beta\n",
    "        # Calculate the profit/loss of the trade\n",
    "        # We Short Stock_A and Long Stock_B\n",
    "        if short_a_long_b:\n",
    "            expected_profit = (stock_a_entry - stock_a_exit) + (stock_b_exit - stock_b_exit)\n",
    "        else:\n",
    "            expected_profit = (stock_a_exit - stock_a_entry) + (stock_b_entry - stock_b_exit)\n",
    "        # Calculate the quantity of Stock_A and Stock_B to trade\n",
    "        if beta > 0:\n",
    "            stock_a_quantity = 1\n",
    "            stock_b_quantity = beta * stock_a_quantity\n",
    "        else:\n",
    "            stock_b_quantity = 1\n",
    "            stock_a_quantity = beta * stock_b_quantity\n",
    "            \n",
    "        # Has this date been traded on before?\n",
    "        if (in_trade and trade_date not in traded_dates and exit_date is not None\n",
    "            and (last_trade_exit_date is None or trade_date > last_trade_exit_date)):\n",
    "\n",
    "            # Add stock_a_exit and stock_b_exit and expected_profit to the trade_entry DataFrame\n",
    "            # Calculate Stock Quantity to trade\n",
    "            df_trade['Trade_Entry'] = trade_date\n",
    "            df_trade['Spread_Mean'] = spread_mean\n",
    "            df_trade['Beta_HedgeRatio'] = beta\n",
    "            df_trade['ShortA_LongB'] = short_a_long_b\n",
    "            df_trade['Stock_A_Entry'] = stock_a_entry\n",
    "            df_trade['Stock_B_Entry'] = stock_b_entry\n",
    "            df_trade['Stock_A_Quantity'] = stock_a_quantity\n",
    "            df_trade['Stock_B_Quantity'] = stock_b_quantity\n",
    "            df_trade['Stock_A_Exit'] = stock_a_exit\n",
    "            df_trade['Stock_B_Exit'] = stock_b_exit\n",
    "            df_trade['Expected_Profit'] = expected_profit\n",
    "            df_trade['Trade_Counter'] = trade_counter\n",
    "            \n",
    "            # Perform the detrended spread analysis from the trade entry date to the end_dt\n",
    "            # simulating the trade as it evolves.\n",
    "            traded_dates.append(trade_date)\n",
    "            trade_dt = datetime.strptime(trade_date, '%Y-%m-%d')\n",
    "            end_dt = trade_dt + pd.Timedelta(days=1)\n",
    "            exit_dt = datetime.strptime(exit_date, '%Y-%m-%d')\n",
    "            short_a_conv = False\n",
    "            long_a_conv = False\n",
    "            while True:\n",
    "                end_dt_str = end_dt.strftime('%Y-%m-%d')\n",
    "                print(f\"Checking convergence between Start Date: {win_date_start},  End Date: {win_date_end} || [{end_dt_str}] ||\")\n",
    "                ppos, df_anl_closes, df_anl_detrend, spread_mean, beta = get_trading_pair_spread((tp1_daily_ppo, tp2_daily_ppo), beta=beta, start_date=win_date_start, end_date=end_dt_str)\n",
    "                ppos_n, df_anl_closes_n, df_anl_detrend_n, spread_mean_n, beta_n = get_trading_pair_spread((tp1_daily_ppo, tp2_daily_ppo), beta=None, start_date=win_date_start, end_date=end_dt_str)\n",
    "\n",
    "                # Check if the current window has a future date where the spread converges to the mean.\n",
    "                if short_a_long_b:\n",
    "                    short_a_conv = df_anl_detrend.iloc[-1]['Spread'] <= spread_mean\n",
    "                elif short_a_long_b is False:\n",
    "                    long_a_conv = df_anl_detrend.iloc[-1]['Spread'] >= spread_mean\n",
    "                    \n",
    "                if short_a_conv or long_a_conv:\n",
    "                    convergence = pd.DataFrame(df_anl_detrend.iloc[-1])\n",
    "                    print(f\"Found Convergence: {end_dt_str}\")    \n",
    "                    break\n",
    "\n",
    "                end_dt = end_dt + timedelta(days=1)\n",
    "            \n",
    "            # Grab the first row in Convergence\n",
    "            df_convergence = {}\n",
    "            if len(convergence) > 0 and in_trade:\n",
    "                # Get the date of the convergence\n",
    "                exit_dt = convergence.iloc[-1].index[0]\n",
    "                exit_date = exit_dt.strftime('%Y-%m-%d')\n",
    "                # Get the current actual price of the Stocks from the df_closes DataFrame\n",
    "                stock_a_exit = df_closes[df_closes.index == exit_dt]['Stock_A']\n",
    "                stock_b_exit = df_closes[df_closes.index == exit_dt]['Stock_B']\n",
    "                \n",
    "                # Add the saved_mean to the df_convergence DataFrame\n",
    "                df_convergence['Trade_Entry'] = trade_date\n",
    "                df_convergence['Trade_Exit'] = exit_date\n",
    "                df_convergence['Spread_Mean'] = saved_spread_mean\n",
    "                df_convergence['New_Spread_Mean'] = spread_mean\n",
    "                df_convergence['Beta_HedgeRatio'] = beta\n",
    "                df_convergence['ShortA_LongB'] = short_a_long_b\n",
    "                \n",
    "                # Add the exit prices to the df_convergence DataFrame\n",
    "                df_convergence['Stock_A_Exit'] = stock_a_exit\n",
    "                df_convergence['Stock_B_Exit'] = stock_b_exit\n",
    "                # Get entry value of Stock_A\n",
    "                entry_value_a = df_trade['Stock_A_Entry'] * df_trade['Stock_A_Quantity']\n",
    "                # Calculate exit value of Stock_B\n",
    "                entry_value_b = df_trade['Stock_B_Entry'] * df_trade['Stock_B_Quantity']\n",
    "                # Calculate the exit value of Stock_A\n",
    "                exit_value_a = df_convergence['Stock_A_Exit'] * df_trade['Stock_A_Quantity']\n",
    "                # Calculate the exit value of Stock_B\n",
    "                exit_value_b= df_convergence['Stock_B_Exit'] * df_trade['Stock_B_Quantity']\n",
    "                # Calculate the profit/loss of the trade\n",
    "                if short_a_long_b:\n",
    "                    profit_loss = (entry_value_a - exit_value_a) + (exit_value_b - entry_value_b)\n",
    "                else:\n",
    "                    profit_loss = (exit_value_a - entry_value_a) + (entry_value_b - exit_value_b)    \n",
    "                # Add the entry_value, exit_value, and profit_loss to the df_convergence DataFrame\n",
    "                df_convergence['Entry_Value'] = entry_value_a + entry_value_b\n",
    "                df_convergence['Exit_Value'] = exit_value_a + exit_value_b\n",
    "                df_convergence['Profit_Loss'] = profit_loss\n",
    "                df_convergence['Trade_Counter'] = trade_counter\n",
    "                \n",
    "                # Add the df_trade row to the df_all_trades DataFrame\n",
    "                if len(df_all_trades) == 0:\n",
    "                    df_all_trades = df_trade\n",
    "                else:\n",
    "                    df_all_trades = pd.concat([df_all_trades, df_trade], axis=1)\n",
    "                # Add the df_convergence row to the df_all_convergence DataFrame\n",
    "                if len(df_all_convergence) == 0:\n",
    "                    df_all_convergence = pd.Series(df_convergence)\n",
    "                else:\n",
    "                    df_all_convergence = pd.concat([df_all_convergence, pd.Series(df_convergence)], axis=1)\n",
    "                \n",
    "                print(f\"[{trade_date}] Trade Exit[{trade_counter}]: Short A Long B: {short_a_long_b}\")\n",
    "                trade_counter += 1\n",
    "                exit_date = None\n",
    "                last_trade_exit_date = trade_date\n",
    "                in_trade = False\n",
    "                short_a_long_b = None\n",
    "            pass\n",
    "        else:\n",
    "            # Trade never converges to the mean\n",
    "            df_trade['Converges'] = False\n",
    "            # TODO: Analyze for stop loss\n",
    "            print(f\"[{trade_date}] Trade Never Converges\")\n",
    "            trade_counter += 1\n",
    "            exit_date = None\n",
    "            in_trade = False\n",
    "            short_a_long_b = None\n",
    "            last_trade_exit_date = trade_date\n",
    "            traded_dates.append(trade_date)\n",
    "            continue\n",
    "            \n",
    "    final_trades = None\n",
    "    if len(df_all_trades) == 0:\n",
    "        print(f\"No Trades were made during the simulation\")\n",
    "    else:\n",
    "        print(f\"Total Trades: {trade_counter}\")\n",
    "        # Clean up the all_trades dataframe\n",
    "        df_all_trades = pd.DataFrame(df_all_trades.transpose())\n",
    "        excluded_columns = ['Stock_A', 'Stock_B', 'Trade_Entry', 'Trade_Exit', df_all_trades.columns[0]]\n",
    "        df_all_trades.loc[:, ~df_all_trades.columns.isin(excluded_columns)] = df_all_trades.loc[:, ~df_all_trades.columns.isin(excluded_columns)].astype(float)\n",
    "        # Clean up the all_convergence dataframe\n",
    "        df_all_convergence = pd.DataFrame(df_all_convergence.transpose())\n",
    "        excluded_columns = ['Stock_A', 'Stock_B', 'Trade_Entry', 'Trade_Exit', df_all_convergence.columns[0]]\n",
    "        df_all_convergence.loc[:, ~df_all_convergence.columns.isin(excluded_columns)] = df_all_convergence.loc[:, ~df_all_convergence.columns.isin(excluded_columns)].astype(float)\n",
    "    \n",
    "        # Merge the all_trades and all_convergence dataframes on the Trade_Counter column, resulting in just the unique columns between the two dataframes.\n",
    "        final_trades = pd.merge(df_all_trades, df_all_convergence, on='Trade_Counter', how='inner')\n",
    "        # Remove columns that end in _a\n",
    "        final_trades = final_trades.loc[:, ~final_trades.columns.str.endswith('_a')]\n",
    "        # Remove columns that end in _b\n",
    "        final_trades = final_trades.loc[:, ~final_trades.columns.str.endswith('_b')]\n",
    "        # Remove columns that end in _x\n",
    "        final_trades = final_trades.loc[:, ~final_trades.columns.str.endswith('_x')]\n",
    "        # Remove columns that end in _y\n",
    "        final_trades = final_trades.loc[:, ~final_trades.columns.str.endswith('_y')]\n",
    "        # Reindex the dataframe\n",
    "        final_trades.reindex(sorted(final_trades['Trade_Counter']), axis=1)\n",
    "\n",
    "    return final_trades\n",
    "\n",
    "\n",
    "trading_pair = ('ACN', 'ZM')\n",
    "trading_days = None\n",
    "# Plot the spread of the trading pair\n",
    "plt = analyze_trading_pair(trading_pair, start_date='2020-01-01', period_len=trading_days, mpl_plt=plt)\n",
    "\n",
    "# Simulate the pairs trading strategy\n",
    "df_all_trades = simulate_pairs_trading(trading_pair, start_date='2020-01-01', period_len=trading_days)\n"
   ],
   "id": "250aba3eb8598824",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Cached PPO: ACN_W\n",
      "Using Cached PPO: ACN_D\n",
      "Using Cached PPO: ZM_W\n",
      "Using Cached PPO: ZM_D\n",
      "Analyze Trading Pair Start Date: 2020-01-01,  End Date: 2025-01-21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "/* Put everything inside the global mpl namespace */\n/* global mpl */\nwindow.mpl = {};\n\nmpl.get_websocket_type = function () {\n    if (typeof WebSocket !== 'undefined') {\n        return WebSocket;\n    } else if (typeof MozWebSocket !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert(\n            'Your browser does not have WebSocket support. ' +\n                'Please try Chrome, Safari or Firefox  6. ' +\n                'Firefox 4 and 5 are also supported but you ' +\n                'have to enable WebSockets in about:config.'\n        );\n    }\n};\n\nmpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = this.ws.binaryType !== undefined;\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById('mpl-warnings');\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent =\n                'This browser does not support binary websocket messages. ' +\n                'Performance may be slow.';\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = document.createElement('div');\n    this.root.setAttribute('style', 'display: inline-block');\n    this._root_extra_style(this.root);\n\n    parent_element.appendChild(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen = function () {\n        fig.send_message('supports_binary', { value: fig.supports_binary });\n        fig.send_message('send_image_mode', {});\n        if (fig.ratio !== 1) {\n            fig.send_message('set_device_pixel_ratio', {\n                device_pixel_ratio: fig.ratio,\n            });\n        }\n        fig.send_message('refresh', {});\n    };\n\n    this.imageObj.onload = function () {\n        if (fig.image_mode === 'full') {\n            // Full images could contain transparency (where diff images\n            // almost always do), so we need to clear the canvas so that\n            // there is no ghosting.\n            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n        }\n        fig.context.drawImage(fig.imageObj, 0, 0);\n    };\n\n    this.imageObj.onunload = function () {\n        fig.ws.close();\n    };\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n};\n\nmpl.figure.prototype._init_header = function () {\n    var titlebar = document.createElement('div');\n    titlebar.classList =\n        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n    var titletext = document.createElement('div');\n    titletext.classList = 'ui-dialog-title';\n    titletext.setAttribute(\n        'style',\n        'width: 100%; text-align: center; padding: 3px;'\n    );\n    titlebar.appendChild(titletext);\n    this.root.appendChild(titlebar);\n    this.header = titletext;\n};\n\nmpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._init_canvas = function () {\n    var fig = this;\n\n    var canvas_div = (this.canvas_div = document.createElement('div'));\n    canvas_div.setAttribute('tabindex', '0');\n    canvas_div.setAttribute(\n        'style',\n        'border: 1px solid #ddd;' +\n            'box-sizing: content-box;' +\n            'clear: both;' +\n            'min-height: 1px;' +\n            'min-width: 1px;' +\n            'outline: 0;' +\n            'overflow: hidden;' +\n            'position: relative;' +\n            'resize: both;' +\n            'z-index: 2;'\n    );\n\n    function on_keyboard_event_closure(name) {\n        return function (event) {\n            return fig.key_event(event, name);\n        };\n    }\n\n    canvas_div.addEventListener(\n        'keydown',\n        on_keyboard_event_closure('key_press')\n    );\n    canvas_div.addEventListener(\n        'keyup',\n        on_keyboard_event_closure('key_release')\n    );\n\n    this._canvas_extra_style(canvas_div);\n    this.root.appendChild(canvas_div);\n\n    var canvas = (this.canvas = document.createElement('canvas'));\n    canvas.classList.add('mpl-canvas');\n    canvas.setAttribute(\n        'style',\n        'box-sizing: content-box;' +\n            'pointer-events: none;' +\n            'position: relative;' +\n            'z-index: 0;'\n    );\n\n    this.context = canvas.getContext('2d');\n\n    var backingStore =\n        this.context.backingStorePixelRatio ||\n        this.context.webkitBackingStorePixelRatio ||\n        this.context.mozBackingStorePixelRatio ||\n        this.context.msBackingStorePixelRatio ||\n        this.context.oBackingStorePixelRatio ||\n        this.context.backingStorePixelRatio ||\n        1;\n\n    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n        'canvas'\n    ));\n    rubberband_canvas.setAttribute(\n        'style',\n        'box-sizing: content-box;' +\n            'left: 0;' +\n            'pointer-events: none;' +\n            'position: absolute;' +\n            'top: 0;' +\n            'z-index: 1;'\n    );\n\n    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n    if (this.ResizeObserver === undefined) {\n        if (window.ResizeObserver !== undefined) {\n            this.ResizeObserver = window.ResizeObserver;\n        } else {\n            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n            this.ResizeObserver = obs.ResizeObserver;\n        }\n    }\n\n    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n        // There's no need to resize if the WebSocket is not connected:\n        // - If it is still connecting, then we will get an initial resize from\n        //   Python once it connects.\n        // - If it has disconnected, then resizing will clear the canvas and\n        //   never get anything back to refill it, so better to not resize and\n        //   keep something visible.\n        if (fig.ws.readyState != 1) {\n            return;\n        }\n        var nentries = entries.length;\n        for (var i = 0; i < nentries; i++) {\n            var entry = entries[i];\n            var width, height;\n            if (entry.contentBoxSize) {\n                if (entry.contentBoxSize instanceof Array) {\n                    // Chrome 84 implements new version of spec.\n                    width = entry.contentBoxSize[0].inlineSize;\n                    height = entry.contentBoxSize[0].blockSize;\n                } else {\n                    // Firefox implements old version of spec.\n                    width = entry.contentBoxSize.inlineSize;\n                    height = entry.contentBoxSize.blockSize;\n                }\n            } else {\n                // Chrome <84 implements even older version of spec.\n                width = entry.contentRect.width;\n                height = entry.contentRect.height;\n            }\n\n            // Keep the size of the canvas and rubber band canvas in sync with\n            // the canvas container.\n            if (entry.devicePixelContentBoxSize) {\n                // Chrome 84 implements new version of spec.\n                canvas.setAttribute(\n                    'width',\n                    entry.devicePixelContentBoxSize[0].inlineSize\n                );\n                canvas.setAttribute(\n                    'height',\n                    entry.devicePixelContentBoxSize[0].blockSize\n                );\n            } else {\n                canvas.setAttribute('width', width * fig.ratio);\n                canvas.setAttribute('height', height * fig.ratio);\n            }\n            /* This rescales the canvas back to display pixels, so that it\n             * appears correct on HiDPI screens. */\n            canvas.style.width = width + 'px';\n            canvas.style.height = height + 'px';\n\n            rubberband_canvas.setAttribute('width', width);\n            rubberband_canvas.setAttribute('height', height);\n\n            // And update the size in Python. We ignore the initial 0/0 size\n            // that occurs as the element is placed into the DOM, which should\n            // otherwise not happen due to the minimum size styling.\n            if (width != 0 && height != 0) {\n                fig.request_resize(width, height);\n            }\n        }\n    });\n    this.resizeObserverInstance.observe(canvas_div);\n\n    function on_mouse_event_closure(name) {\n        /* User Agent sniffing is bad, but WebKit is busted:\n         * https://bugs.webkit.org/show_bug.cgi?id=144526\n         * https://bugs.webkit.org/show_bug.cgi?id=181818\n         * The worst that happens here is that they get an extra browser\n         * selection when dragging, if this check fails to catch them.\n         */\n        var UA = navigator.userAgent;\n        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);\n        if(isWebKit) {\n            return function (event) {\n                /* This prevents the web browser from automatically changing to\n                 * the text insertion cursor when the button is pressed. We\n                 * want to control all of the cursor setting manually through\n                 * the 'cursor' event from matplotlib */\n                event.preventDefault()\n                return fig.mouse_event(event, name);\n            };\n        } else {\n            return function (event) {\n                return fig.mouse_event(event, name);\n            };\n        }\n    }\n\n    canvas_div.addEventListener(\n        'mousedown',\n        on_mouse_event_closure('button_press')\n    );\n    canvas_div.addEventListener(\n        'mouseup',\n        on_mouse_event_closure('button_release')\n    );\n    canvas_div.addEventListener(\n        'dblclick',\n        on_mouse_event_closure('dblclick')\n    );\n    // Throttle sequential mouse events to 1 every 20ms.\n    canvas_div.addEventListener(\n        'mousemove',\n        on_mouse_event_closure('motion_notify')\n    );\n\n    canvas_div.addEventListener(\n        'mouseenter',\n        on_mouse_event_closure('figure_enter')\n    );\n    canvas_div.addEventListener(\n        'mouseleave',\n        on_mouse_event_closure('figure_leave')\n    );\n\n    canvas_div.addEventListener('wheel', function (event) {\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        on_mouse_event_closure('scroll')(event);\n    });\n\n    canvas_div.appendChild(canvas);\n    canvas_div.appendChild(rubberband_canvas);\n\n    this.rubberband_context = rubberband_canvas.getContext('2d');\n    this.rubberband_context.strokeStyle = '#000000';\n\n    this._resize_canvas = function (width, height, forward) {\n        if (forward) {\n            canvas_div.style.width = width + 'px';\n            canvas_div.style.height = height + 'px';\n        }\n    };\n\n    // Disable right mouse context menu.\n    canvas_div.addEventListener('contextmenu', function (_e) {\n        event.preventDefault();\n        return false;\n    });\n\n    function set_focus() {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'mpl-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'mpl-button-group';\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'mpl-button-group';\n            continue;\n        }\n\n        var button = (fig.buttons[name] = document.createElement('button'));\n        button.classList = 'mpl-widget';\n        button.setAttribute('role', 'button');\n        button.setAttribute('aria-disabled', 'false');\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n\n        var icon_img = document.createElement('img');\n        icon_img.src = '_images/' + image + '.png';\n        icon_img.srcset = '_images/' + image + '_large.png 2x';\n        icon_img.alt = tooltip;\n        button.appendChild(icon_img);\n\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    var fmt_picker = document.createElement('select');\n    fmt_picker.classList = 'mpl-widget';\n    toolbar.appendChild(fmt_picker);\n    this.format_dropdown = fmt_picker;\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = document.createElement('option');\n        option.selected = fmt === mpl.default_extension;\n        option.innerHTML = fmt;\n        fmt_picker.appendChild(option);\n    }\n\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n};\n\nmpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', { width: x_pixels, height: y_pixels });\n};\n\nmpl.figure.prototype.send_message = function (type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n};\n\nmpl.figure.prototype.send_draw_message = function () {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n};\n\nmpl.figure.prototype.handle_resize = function (fig, msg) {\n    var size = msg['size'];\n    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1], msg['forward']);\n        fig.send_message('refresh', {});\n    }\n};\n\nmpl.figure.prototype.handle_rubberband = function (fig, msg) {\n    var x0 = msg['x0'] / fig.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n    var x1 = msg['x1'] / fig.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0,\n        0,\n        fig.canvas.width / fig.ratio,\n        fig.canvas.height / fig.ratio\n    );\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n};\n\nmpl.figure.prototype.handle_figure_label = function (fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n};\n\nmpl.figure.prototype.handle_cursor = function (fig, msg) {\n    fig.canvas_div.style.cursor = msg['cursor'];\n};\n\nmpl.figure.prototype.handle_message = function (fig, msg) {\n    fig.message.textContent = msg['message'];\n};\n\nmpl.figure.prototype.handle_draw = function (fig, _msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n};\n\nmpl.figure.prototype.handle_image_mode = function (fig, msg) {\n    fig.image_mode = msg['mode'];\n};\n\nmpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n    for (var key in msg) {\n        if (!(key in fig.buttons)) {\n            continue;\n        }\n        fig.buttons[key].disabled = !msg[key];\n        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n    }\n};\n\nmpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n    if (msg['mode'] === 'PAN') {\n        fig.buttons['Pan'].classList.add('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    } else if (msg['mode'] === 'ZOOM') {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.add('active');\n    } else {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    }\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Called whenever the canvas gets updated.\n    this.send_message('ack', {});\n};\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function (fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            var img = evt.data;\n            if (img.type !== 'image/png') {\n                /* FIXME: We get \"Resource interpreted as Image but\n                 * transferred with MIME type text/plain:\" errors on\n                 * Chrome.  But how to set the MIME type?  It doesn't seem\n                 * to be part of the websocket stream */\n                img.type = 'image/png';\n            }\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src\n                );\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                img\n            );\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        } else if (\n            typeof evt.data === 'string' &&\n            evt.data.slice(0, 21) === 'data:image/png;base64'\n        ) {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig['handle_' + msg_type];\n        } catch (e) {\n            console.log(\n                \"No handler for the '\" + msg_type + \"' message type: \",\n                msg\n            );\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\n                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n                    e,\n                    e.stack,\n                    msg\n                );\n            }\n        }\n    };\n};\n\nfunction getModifiers(event) {\n    var mods = [];\n    if (event.ctrlKey) {\n        mods.push('ctrl');\n    }\n    if (event.altKey) {\n        mods.push('alt');\n    }\n    if (event.shiftKey) {\n        mods.push('shift');\n    }\n    if (event.metaKey) {\n        mods.push('meta');\n    }\n    return mods;\n}\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * https://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys(original) {\n    return Object.keys(original).reduce(function (obj, key) {\n        if (typeof original[key] !== 'object') {\n            obj[key] = original[key];\n        }\n        return obj;\n    }, {});\n}\n\nmpl.figure.prototype.mouse_event = function (event, name) {\n    if (name === 'button_press') {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    // from https://stackoverflow.com/q/1114465\n    var boundingRect = this.canvas.getBoundingClientRect();\n    var x = (event.clientX - boundingRect.left) * this.ratio;\n    var y = (event.clientY - boundingRect.top) * this.ratio;\n\n    this.send_message(name, {\n        x: x,\n        y: y,\n        button: event.button,\n        step: event.step,\n        modifiers: getModifiers(event),\n        guiEvent: simpleKeys(event),\n    });\n\n    return false;\n};\n\nmpl.figure.prototype._key_event_extra = function (_event, _name) {\n    // Handle any extra behaviour associated with a key event\n};\n\nmpl.figure.prototype.key_event = function (event, name) {\n    // Prevent repeat events\n    if (name === 'key_press') {\n        if (event.key === this._key) {\n            return;\n        } else {\n            this._key = event.key;\n        }\n    }\n    if (name === 'key_release') {\n        this._key = null;\n    }\n\n    var value = '';\n    if (event.ctrlKey && event.key !== 'Control') {\n        value += 'ctrl+';\n    }\n    else if (event.altKey && event.key !== 'Alt') {\n        value += 'alt+';\n    }\n    else if (event.shiftKey && event.key !== 'Shift') {\n        value += 'shift+';\n    }\n\n    value += 'k' + event.key;\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n    return false;\n};\n\nmpl.figure.prototype.toolbar_button_onclick = function (name) {\n    if (name === 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message('toolbar_button', { name: name });\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n    this.message.textContent = tooltip;\n};\n\n///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n// prettier-ignore\nvar _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\", \"webp\"];\n\nmpl.default_extension = \"png\";/* global mpl */\n\nvar comm_websocket_adapter = function (comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.binaryType = comm.kernel.ws.binaryType;\n    ws.readyState = comm.kernel.ws.readyState;\n    function updateReadyState(_event) {\n        if (comm.kernel.ws) {\n            ws.readyState = comm.kernel.ws.readyState;\n        } else {\n            ws.readyState = 3; // Closed state.\n        }\n    }\n    comm.kernel.ws.addEventListener('open', updateReadyState);\n    comm.kernel.ws.addEventListener('close', updateReadyState);\n    comm.kernel.ws.addEventListener('error', updateReadyState);\n\n    ws.close = function () {\n        comm.close();\n    };\n    ws.send = function (m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function (msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        var data = msg['content']['data'];\n        if (data['blob'] !== undefined) {\n            data = {\n                data: new Blob(msg['buffers'], { type: data['blob'] }),\n            };\n        }\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(data);\n    });\n    return ws;\n};\n\nmpl.mpl_figure_comm = function (comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = document.getElementById(id);\n    var ws_proxy = comm_websocket_adapter(comm);\n\n    function ondownload(figure, _format) {\n        window.open(figure.canvas.toDataURL());\n    }\n\n    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element;\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error('Failed to find cell for figure', id, fig);\n        return;\n    }\n    fig.cell_info[0].output_area.element.on(\n        'cleared',\n        { fig: fig },\n        fig._remove_fig_handler\n    );\n};\n\nmpl.figure.prototype.handle_close = function (fig, msg) {\n    var width = fig.canvas.width / fig.ratio;\n    fig.cell_info[0].output_area.element.off(\n        'cleared',\n        fig._remove_fig_handler\n    );\n    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable();\n    fig.parent_element.innerHTML =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n    fig.close_ws(fig, msg);\n};\n\nmpl.figure.prototype.close_ws = function (fig, msg) {\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n};\n\nmpl.figure.prototype.push_to_output = function (_remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width / this.ratio;\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message('ack', {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () {\n        fig.push_to_output();\n    }, 1000);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'btn-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'btn-group';\n    var button;\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'btn-group';\n            continue;\n        }\n\n        button = fig.buttons[name] = document.createElement('button');\n        button.classList = 'btn btn-default';\n        button.href = '#';\n        button.title = name;\n        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    // Add the status bar.\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message pull-right';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n\n    // Add the close button to the window.\n    var buttongrp = document.createElement('div');\n    buttongrp.classList = 'btn-group inline pull-right';\n    button = document.createElement('button');\n    button.classList = 'btn btn-mini btn-primary';\n    button.href = '#';\n    button.title = 'Stop Interaction';\n    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n    button.addEventListener('click', function (_evt) {\n        fig.handle_close(fig, {});\n    });\n    button.addEventListener(\n        'mouseover',\n        on_mouseover_closure('Stop Interaction')\n    );\n    buttongrp.appendChild(button);\n    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n};\n\nmpl.figure.prototype._remove_fig_handler = function (event) {\n    var fig = event.data.fig;\n    if (event.target !== this) {\n        // Ignore bubbled events from children.\n        return;\n    }\n    fig.close_ws(fig, {});\n};\n\nmpl.figure.prototype._root_extra_style = function (el) {\n    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n};\n\nmpl.figure.prototype._canvas_extra_style = function (el) {\n    // this is important to make the div 'focusable\n    el.setAttribute('tabindex', 0);\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    } else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n};\n\nmpl.figure.prototype._key_event_extra = function (event, _name) {\n    // Check for shift+enter\n    if (event.shiftKey && event.which === 13) {\n        this.canvas_div.blur();\n        // select the cell after this one\n        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n        IPython.notebook.select(index + 1);\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    fig.ondownload(fig, null);\n};\n\nmpl.find_output_cell = function (html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i = 0; i < ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code') {\n            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] === html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n};\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel !== null) {\n    IPython.notebook.kernel.comm_manager.register_target(\n        'matplotlib',\n        mpl.mpl_figure_comm\n    );\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div id='6b8d8b1c-0682-4d37-ad4e-891553208e49'></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily[2020-01-01 to 2025-01-21 00:00:00] Hedge Ratio 2.13959566779732\n",
      "Using Cached PPO: ACN_W\n",
      "Using Cached PPO: ACN_D\n",
      "Using Cached PPO: ZM_W\n",
      "Using Cached PPO: ZM_D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Date: 2020-01-02 00:00:00,  End Date: 2025-01-17 00:00:00\n",
      "Divergence Window Start Date: 2020-01-05 00:00:00,  End Date: 2020-02-04 00:00:00\n",
      "No more Tradeable Spreads found... Exiting\n",
      "No Trades were made during the simulation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "print(f\"Toal Profit/Loss: {df_all_trades['Profit_Loss'].sum()}\")\n",
    "df_all_trades\n"
   ],
   "id": "b3e1fa736db487a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_all_convergence['Profit_Loss'].sum()",
   "id": "5a960219342861d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T22:43:15.053068Z",
     "start_time": "2025-01-20T22:43:14.964125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Analyze PP Objects\n",
    "ppos = ('UPS', 'PTCT')\n",
    "# Get or create the required Trading Pair PPOs\n",
    "ppo1_w, ppo1_d, ppo2_w, ppo2_d = get_tradingpair_ppos(ppos)\n",
    "\n",
    "ObjCache.keys()\n"
   ],
   "id": "9e67f5f03d7de873",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_tradingpair_ppos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m ppos \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTSLA\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAAPL\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Get or create the required Trading Pair PPOs\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m ppo1_w, ppo1_d, ppo2_w, ppo2_d \u001B[38;5;241m=\u001B[39m \u001B[43mget_tradingpair_ppos\u001B[49m(ppos)\n\u001B[1;32m      6\u001B[0m ObjCache\u001B[38;5;241m.\u001B[39mkeys()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'get_tradingpair_ppos' is not defined"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
